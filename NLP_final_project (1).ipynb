{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "DATA_DIR = \"./data_2/\"\n",
    "data_files = [file for file in glob(DATA_DIR+\"results_*.pkl\")]\n",
    "data = defaultdict(int)\n",
    "for dataset in tqdm(data_files):\n",
    "    start = dataset.find('A')\n",
    "    end = dataset.find('.pkl')\n",
    "    id = dataset[start:end]\n",
    "    with open(dataset,\"rb\") as f:\n",
    "       dataset = pickle.load(f)\n",
    "       data[id] = dataset\n",
    "\n",
    "with open('alldata.pkl',\"wb\") as f:\n",
    "    pickle.dump(data,f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.dgl.ai/wheels/torch-2.1/repo.html\n",
      "Collecting dgl\n",
      "  Downloading https://data.dgl.ai/wheels/torch-2.1/dgl-2.4.0-cp311-cp311-manylinux1_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (3.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (1.26.4)\n",
      "Requirement already satisfied: packaging in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (24.1)\n",
      "Requirement already satisfied: pandas in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (6.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (1.14.0)\n",
      "Requirement already satisfied: tqdm in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (4.66.4)\n",
      "Requirement already satisfied: torch<=2.4.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from dgl) (2.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from pydantic>=2.0->dgl) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from pydantic>=2.0->dgl) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2024.7.4)\n",
      "Requirement already satisfied: filelock in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (3.15.4)\n",
      "Requirement already satisfied: sympy in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (1.13.0)\n",
      "Requirement already satisfied: jinja2 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch<=2.4.0->dgl) (2024.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from pandas->dgl) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from pandas->dgl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from pandas->dgl) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from jinja2->torch<=2.4.0->dgl) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.1/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"alldata.pkl\",\"rb\") as f:\n",
    "       data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for (id,sample) in processed_samples.items():\n",
    "    data.append(list(sample.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:00<00:06,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 285 and 292 instead. with A39-23\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 300 and 306 instead. with A39-24\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 295 and 296 instead. with A39-27\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 286 and 295 instead. with A39-29\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 204 and 341 instead. with A39-43\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 347 and 358 instead. with A39-44\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 336 and 371 instead. with A39-45\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 289 and 290 instead. with A03-12\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 310 and 313 instead. with A03-28\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 311 and 313 instead. with A03-30\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 311 and 312 instead. with A03-31\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 265 and 268 instead. with A27-12\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 248 and 272 instead. with A27-13\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 292 and 297 instead. with A27-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:00<00:05,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 236 and 248 instead. with A27-38\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 283 and 285 instead. with A24-4\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 275 and 279 instead. with A24-5\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 297 and 302 instead. with A24-6\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 291 and 297 instead. with A24-7\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 301 and 303 instead. with A24-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [00:01<00:04,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 311 and 313 instead. with A19-8\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 292 and 295 instead. with A19-11\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 291 and 295 instead. with A19-12\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 281 and 283 instead. with A19-13\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 283 and 285 instead. with A19-15\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 280 and 285 instead. with A19-16\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 283 and 285 instead. with A19-18\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 282 and 290 instead. with A19-21\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 267 and 276 instead. with A19-22\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 277 and 283 instead. with A19-23\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 277 and 295 instead. with A19-31\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 317 and 318 instead. with A19-37\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 310 and 313 instead. with A19-39\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 315 and 316 instead. with A19-41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [00:01<00:04,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 403 and 443 instead. with A31-26\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 405 and 437 instead. with A31-27\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 496 and 522 instead. with A04-3\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 491 and 532 instead. with A04-6\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 488 and 527 instead. with A04-9\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 495 and 523 instead. with A04-11\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 483 and 655 instead. with A04-15\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 464 and 519 instead. with A04-17\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 465 and 589 instead. with A04-19\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 365 and 366 instead. with A04-21\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 457 and 564 instead. with A04-23\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 295 and 296 instead. with A32-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [00:01<00:03,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 274 and 281 instead. with A15-18\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 319 and 320 instead. with A17-37\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 114 and 115 instead. with A17-38\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 288 and 292 instead. with A21-9\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 280 and 282 instead. with A21-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [00:02<00:03,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 375 and 378 instead. with A21-17\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 297 and 298 instead. with A28-6\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 290 and 291 instead. with A28-9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [00:02<00:02,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 327 and 328 instead. with A37-21\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 320 and 322 instead. with A37-22\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 300 and 301 instead. with A33-20\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 370 and 395 instead. with A33-21\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 371 and 376 instead. with A33-22\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 268 and 289 instead. with A33-23\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 298 and 300 instead. with A06-9\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 288 and 290 instead. with A06-11\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 300 and 311 instead. with A06-15\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 301 and 305 instead. with A06-16\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 285 and 286 instead. with A06-17\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 289 and 290 instead. with A06-20\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 312 and 313 instead. with A06-29\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 316 and 317 instead. with A06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [00:02<00:02,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 285 and 286 instead. with A36-17\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 301 and 302 instead. with A36-18\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 283 and 284 instead. with A36-19\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 376 and 378 instead. with A36-30\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 375 and 381 instead. with A36-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [00:03<00:03,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 355 and 356 instead. with A14-27\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 376 and 400 instead. with A30-26\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 365 and 399 instead. with A30-27\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 392 and 405 instead. with A30-28\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 284 and 286 instead. with A11-10\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 289 and 291 instead. with A11-11\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 284 and 286 instead. with A11-12\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 272 and 276 instead. with A11-16\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 271 and 276 instead. with A11-17\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 300 and 301 instead. with A11-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [00:03<00:02,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 278 and 280 instead. with A11-32\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 351 and 353 instead. with A11-33\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 355 and 366 instead. with A11-34\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 275 and 285 instead. with A13-11\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 275 and 277 instead. with A13-13\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 266 and 267 instead. with A13-14\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 261 and 262 instead. with A13-15\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 262 and 264 instead. with A13-16\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 286 and 287 instead. with A13-18\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 307 and 308 instead. with A13-19\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 285 and 289 instead. with A13-31\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 270 and 273 instead. with A13-33\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 255 and 263 instead. with A13-34\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 252 and 260 instead. with A13-35\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 273 and 274 instead. with A13-36\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 269 and 270 instead. with A09-6\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 267 and 268 instead. with A09-8\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 270 and 273 instead. with A09-11\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 278 and 279 instead. with A09-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [00:03<00:01,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 285 and 286 instead. with A07-1\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 492 and 514 instead. with A07-3\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 475 and 519 instead. with A07-9\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 486 and 528 instead. with A07-10\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 489 and 528 instead. with A07-13\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 489 and 520 instead. with A07-15\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 484 and 517 instead. with A07-16\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 491 and 522 instead. with A07-17\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 486 and 764 instead. with A07-20\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 336 and 337 instead. with A07-21\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 477 and 563 instead. with A07-23\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 313 and 314 instead. with A22-0\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 307 and 308 instead. with A22-6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [00:03<00:01,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 324 and 326 instead. with A22-38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [00:04<00:02,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 326 and 327 instead. with A02-27\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 283 and 285 instead. with A20-2\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 293 and 296 instead. with A20-7\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 314 and 317 instead. with A20-8\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 292 and 296 instead. with A20-10\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 284 and 287 instead. with A20-11\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 285 and 291 instead. with A20-12\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 273 and 277 instead. with A20-13\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 278 and 284 instead. with A20-14\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 283 and 289 instead. with A20-15\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 262 and 263 instead. with A20-18\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 304 and 305 instead. with A20-21\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 277 and 278 instead. with A20-22\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 292 and 293 instead. with A20-32\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 314 and 316 instead. with A20-35\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 313 and 316 instead. with A20-36\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 308 and 309 instead. with A29-3\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 287 and 288 instead. with A29-14\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 278 and 282 instead. with A29-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [00:04<00:01,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 380 and 381 instead. with A29-26\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 387 and 404 instead. with A29-28\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 391 and 398 instead. with A29-29\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 342 and 343 instead. with A29-31\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 135 and 136 instead. with A29-33\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 286 and 292 instead. with A26-15\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 268 and 272 instead. with A26-16\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 275 and 278 instead. with A26-17\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 284 and 286 instead. with A26-19\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 280 and 281 instead. with A26-20\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 286 and 287 instead. with A26-22\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 332 and 333 instead. with A26-37\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 336 and 337 instead. with A26-38\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 286 and 287 instead. with A38-6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [00:05<00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 250 and 293 instead. with A38-21\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 200 and 250 instead. with A38-22\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 278 and 282 instead. with A25-14\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 368 and 371 instead. with A25-21\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 281 and 282 instead. with A10-9\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 266 and 270 instead. with A10-10\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 279 and 285 instead. with A10-14\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 275 and 281 instead. with A10-15\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 336 and 337 instead. with A10-16\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 353 and 355 instead. with A10-23\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 373 and 379 instead. with A10-24\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 379 and 388 instead. with A10-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [00:05<00:00,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 283 and 284 instead. with A40-0\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 363 and 370 instead. with A40-17\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 280 and 289 instead. with A16-11\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 364 and 366 instead. with A16-28\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 370 and 372 instead. with A16-29\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 342 and 355 instead. with A34-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:06<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 328 and 329 instead. with A12-28\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 314 and 316 instead. with A12-30\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 251 and 283 instead. with A05-20\n",
      "error adding embeddings as node features Expect number of features to match number of nodes (len(u)). Got 288 and 290 instead. with A05-21\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x148292d79b20>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 110\u001b[0m\n\u001b[1;32m    106\u001b[0m                 processed_samples[sample_id][layer] \u001b[38;5;241m=\u001b[39m layer_to_graph(embeds,adj,sample_id)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_samples.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x148292d79b20>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def np_to_dgl(np_adj):\n",
    "    # Convert to SciPy sparse matrix\n",
    "    sparse_matrix = sp.coo_matrix(np_adj)\n",
    "\n",
    "    # Convert to DGL graph\n",
    "    g = dgl.from_scipy(sparse_matrix)\n",
    "\n",
    "    return g\n",
    "\n",
    "def add_embedding_features(g,features,sample_id):\n",
    "    try:\n",
    "        (num_nodes,num_dims) = features.shape\n",
    "\n",
    "        initial_features = torch.zeros((num_nodes, num_dims))  # All features initialized to 0\n",
    "        g.ndata['feat'] = initial_features\n",
    "\n",
    "        g.ndata['feat'] = features\n",
    "\n",
    "        return g\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f'error adding embeddings as node features {e} with {sample_id}')\n",
    "\n",
    "def layer_to_graph(embeddings,adj,sample_id):\n",
    "    g = np_to_dgl(adj)\n",
    "\n",
    "    return add_embedding_features(g,embeddings,sample_id)\n",
    "\n",
    "\n",
    "def embed_label(labels,embedding_dim):\n",
    "    \"\"\"\n",
    "    labels: str list\n",
    "    \n",
    "    \"\"\"\n",
    "    # Step 1: Map string labels to integer indices\n",
    "    label_to_index = {label: idx for idx, label in enumerate(set(labels))}\n",
    "    encoded_labels = [label_to_index[label] for label in labels]\n",
    "\n",
    "    # Step 2: Create a learnable embedding layer\n",
    "    embedding_dim = 4  # Desired embedding dimension\n",
    "    num_labels = len(label_to_index)  # Number of unique labels\n",
    "    \n",
    "    # Create an embedding layer\n",
    "    embedding_layer = nn.Embedding(num_labels, embedding_dim)\n",
    "    \n",
    "    # Step 3: Use the embedding layer to get compressed vectors\n",
    "    indices = torch.tensor(encoded_labels)\n",
    "    embedded_vectors = embedding_layer(indices)\n",
    "\n",
    "    return embedded_vectors\n",
    "\n",
    "def parse_labels(labels):\n",
    "    new_labels = [[] for _ in range(4)]\n",
    "    for (id,pos,relations) in labels:\n",
    "        if \"<\" in id or \">\" in id:\n",
    "            id = \"\"\n",
    "        if type(relations) != tuple:\n",
    "            relations = (\"\",\"\")\n",
    "        relation_type = relations[0]\n",
    "        relation = relations[1]\n",
    "        new_labels[0].append(id)\n",
    "        new_labels[1].append(pos)\n",
    "        new_labels[2].append(relation_type)\n",
    "        new_labels[3].append(relation)\n",
    "    return new_labels\n",
    "\n",
    "with open(\"alldata.pkl\",\"rb\") as f:\n",
    "       data = pickle.load(f)\n",
    "\n",
    "processed_samples = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for (paper,samples) in tqdm(data.items()):\n",
    "    for (i,sample) in enumerate(samples):\n",
    "        [text,labels,layers] = sample\n",
    "        \n",
    "        sample_id = paper+\"-\"+str(i)\n",
    "        \n",
    "        [ids,poss,relation_type,relation] = parse_labels(labels)\n",
    "\n",
    "        processed_samples[sample_id]['label'] = list(zip(\n",
    "            embed_label(ids,13),\n",
    "            embed_label(poss,6),\n",
    "            embed_label(relation_type,3),\n",
    "            embed_label(relation,13)))\n",
    "        i = 0\n",
    "        for (layer,v) in layers.items():\n",
    "            if layer != 'masks':\n",
    "                embeds = v[0]\n",
    "                adj = v[1]\n",
    "                \"\"\"\n",
    "                if len(embeds) != len(adj) and i<5:\n",
    "                    print(sample_id)\n",
    "                    print(text)\n",
    "                    i+=1\n",
    "                    \"\"\"\n",
    "                processed_samples[sample_id][layer] = layer_to_graph(embeds,adj,sample_id)\n",
    "       \n",
    "\n",
    "with open(\"processed_samples.pkl\",\"wb\") as f:\n",
    "    pickle.dump(processed_samples,f)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb,adj = data[\"A05\"][20][2]['layer_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n . \\uf8ee \\uf8ef \\uf8f0 (T (T 2,e 2,e 1 k − − . . . T T 1,e 1,e k 1 )v )v d d ··· ··· .. . (T (T n,e n,e 1 k − − . . . T T 1,e 1,e k 1 )v )v d d \\uf8f9 \\uf8fb \\uf8fa \\uf8f0 \\uf8ee \\uf8ef \\uf8ef w w w . . . 2 n 3 \\uf8fa \\uf8fb \\uf8fa \\uf8f9 = \\uf8ef \\uf8f0 \\uf8ee v v e e 1 k − − T T . . . 1,e 1,e 1 k v v d d \\uf8f9 \\uf8fa \\uf8fb 5 To appear at SIGGRAPH 2003 The matrix used to solve for vertex positions is as follows. \\uf8ee \\uf8f0 \\uf8ef ∑ ∑ i=1 n i=1 n w w . . . i i T T i,e i,e 1 k \\uf8f9 \\uf8fa \\uf8fb v d = \\uf8f0 \\uf8ef \\uf8ee v v . . . e e 1 k \\uf8fa \\uf8fb \\uf8f9 To handle homogeneous coordinates, the translation parts of the ∑ i=1 n w i T i,e k matrices are subtracted from the v e on the right hand side. We solve these least-squares problems using the singular value decomposition. This lets us detect when our matrices are rank deficient, leading to overfitting. We detect this by comparing the ratio of the largest singular value to the smallest, and issuing a warning if there are any singular values below some fraction of this ratio. To recover, we zero these singular values and'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"A05\"][20][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 283)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example HGT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dgl.nn import HGTLayer\n",
    "\n",
    "class TwoLayerHGT(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_heads, num_node_types, num_edge_types, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - in_dim: Input feature dimension for each node type.\n",
    "        - hidden_dim: Dimension of hidden representations.\n",
    "        - out_dim: Dimension of output features.\n",
    "        - num_heads: Number of attention heads in HGT layers.\n",
    "        - num_node_types: Number of unique node types.\n",
    "        - num_edge_types: Number of unique edge types.\n",
    "        - dropout: Dropout rate.\n",
    "        \"\"\"\n",
    "        super(TwoLayerHGT, self).__init__()\n",
    "        self.node_type_emb = nn.Embedding(num_node_types, hidden_dim)  # Node type embeddings\n",
    "        self.input_proj = nn.Linear(in_dim, hidden_dim)  # Project input to hidden_dim\n",
    "        \n",
    "        # Two HGT layers\n",
    "        self.hgt_layer1 = HGTLayer(hidden_dim, hidden_dim, num_heads, num_node_types, num_edge_types, dropout)\n",
    "        self.hgt_layer2 = HGTLayer(hidden_dim, hidden_dim, num_heads, num_node_types, num_edge_types, dropout)\n",
    "        \n",
    "        self.output_proj = nn.Linear(hidden_dim, out_dim)  # Project hidden to output_dim\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, g, node_features):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - g: Heterogeneous DGLGraph.\n",
    "        - node_features: Dictionary of input node features for each node type.\n",
    "          Example: {'type1': tensor, 'type2': tensor, ...}\n",
    "        \"\"\"\n",
    "        # Project input features to a common hidden space\n",
    "        h = {\n",
    "            ntype: self.input_proj(node_features[ntype])\n",
    "            for ntype in g.ntypes\n",
    "        }\n",
    "        \n",
    "        # Add node type embeddings\n",
    "        for ntype in g.ntypes:\n",
    "            h[ntype] += self.node_type_emb.weight[g.get_ntype_id(ntype)]\n",
    "        \n",
    "        # First HGT layer\n",
    "        h = self.hgt_layer1(g, h)\n",
    "        h = {k: torch.relu(v) for k, v in h.items()}  # Apply non-linearity\n",
    "        \n",
    "        # Second HGT layer\n",
    "        h = self.hgt_layer2(g, h)\n",
    "        h = {k: torch.relu(v) for k, v in h.items()}  # Apply non-linearity\n",
    "        \n",
    "        # Output projection\n",
    "        h = {\n",
    "            ntype: self.output_proj(self.dropout(h[ntype]))\n",
    "            for ntype in g.ntypes\n",
    "        }\n",
    "        return h\n",
    "\n",
    "# Example usage:\n",
    "# Initialize the model\n",
    "model = TwoLayerHGT(\n",
    "    in_dim=128, \n",
    "    hidden_dim=64, \n",
    "    out_dim=32, \n",
    "    num_heads=4, \n",
    "    num_node_types=3, \n",
    "    num_edge_types=4, \n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "# Example graph and input features\n",
    "import dgl\n",
    "import torch\n",
    "\n",
    "# Define a simple heterogeneous graph\n",
    "graph_data = {\n",
    "    ('paper', 'cites', 'paper'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
    "    ('author', 'writes', 'paper'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
    "}\n",
    "g = dgl.heterograph(graph_data)\n",
    "\n",
    "# Example node features\n",
    "node_features = {\n",
    "    'paper': torch.randn(3, 128),  # 3 papers with 128-dimensional features\n",
    "    'author': torch.randn(2, 128),  # 2 authors with 128-dimensional features\n",
    "}\n",
    "\n",
    "# Forward pass\n",
    "output = model(g, node_features)\n",
    "dgl.save_graphs(\"graph.dgl\", g)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "\n",
    "\n",
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    all_logits = []\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    \"\"\"\n",
    "    features = g.ndata[\"feat\"]\n",
    "    labels = g.ndata[\"label\"]\n",
    "    train_mask = g.ndata[\"train_mask\"]\n",
    "    val_mask = g.ndata[\"val_mask\"]\n",
    "    test_mask = g.ndata[\"test_mask\"]\n",
    "    \"\"\"\n",
    "    for e in range(20):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that we should only compute the losses of the nodes in the training set,\n",
    "        # i.e. with train_mask 1.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_logits.append(logits.detach())\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print(\n",
    "                \"In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})\".format(\n",
    "                    e, loss, val_acc, best_val_acc, test_acc, best_test_acc\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "model = Model(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlst_samples.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open(\"lst_samples.pkl\",\"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "\n",
    "def add_self_loops_to_graphs(graphs):\n",
    "    \"\"\"\n",
    "    Add self-loops to a list of DGL graphs.\n",
    "    Parameters:\n",
    "    - graphs: List of DGLGraph objects.\n",
    "    Returns:\n",
    "    - List of DGLGraph objects with self-loops added.\n",
    "    \"\"\"\n",
    "    return [dgl.add_self_loop(g) for g in graphs]\n",
    "total_samples = 0\n",
    "problems = 0\n",
    "filtered_data = []\n",
    "for (y,datapoint) in enumerate(data):\n",
    "    if len(datapoint) == 4:\n",
    "        for i in range(1, 4):  # g1, g2, g3\n",
    "            if isinstance(datapoint[i], dgl.DGLGraph):  # Ensure the graph exists\n",
    "                datapoint[i] = dgl.add_self_loop(datapoint[i])\n",
    "            else:\n",
    "                #print(f\"{i}{y}\")\n",
    "                problems+=1\n",
    "        filtered_data.append(datapoint)\n",
    "    total_samples+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_graphs(gs):\n",
    "    for g in gs:\n",
    "        if not(isinstance(g, dgl.DGLGraph)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "x = [check_graphs([g1,g2,g3]) for [label,g1,g2,g3] in filtered_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_filter = []\n",
    "for i,b in enumerate(x):\n",
    "    if b:\n",
    "        second_filter.append(filtered_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_labels(label):\n",
    "    if len(label) == 250:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "x = [check_labels(label) for [label,g1,g2,g3] in second_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_filter = []\n",
    "for i,b in enumerate(x):\n",
    "    if b:\n",
    "        third_filter.append(second_filter[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_graph_features(graph_list):\n",
    "    for g in graph_list:\n",
    "        if not('feat' in g.ndata):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "checks = [i for (i,[_,g1,g2,g3]) in enumerate(third_filter) if check_graph_features([g1,g2,g3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/792 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2712x64 and 512x192)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 213\u001b[0m\n\u001b[1;32m    210\u001b[0m decoder \u001b[38;5;241m=\u001b[39m Decoder(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m192\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m    211\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mlist\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(decoder\u001b[38;5;241m.\u001b[39mparameters()), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m--> 213\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 150\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, decoder, optimizer, train_data, val_data, list_length, num_epochs)\u001b[0m\n\u001b[1;32m    147\u001b[0m target, batched_graphs \u001b[38;5;241m=\u001b[39m process_datapoint(datapoint, model)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m graph_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatched_graphs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Output: (3, 64)\u001b[39;00m\n\u001b[1;32m    151\u001b[0m graph_embeddings \u001b[38;5;241m=\u001b[39m graph_embeddings\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape to (batch_size, input_dim * 3), e.g., (1, 192)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m train_outputs \u001b[38;5;241m=\u001b[39m decoder(graph_embeddings)  \u001b[38;5;66;03m# Shape: (batch_size, list_length, 4)\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[73], line 72\u001b[0m, in \u001b[0;36mBATCHGAT.forward\u001b[0;34m(self, graph, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#x = x.mean(dim=2)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Final Classification Layer\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2712x64 and 512x192)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits as loss_fn\n",
    "\n",
    "class GCNEncoder_vanilla(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.gcn1 = GraphConv(input_dim, hidden_dim)\n",
    "        self.gcn2 = GraphConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        if not isinstance(graph, dgl.DGLGraph):\n",
    "            raise TypeError(\"Input must be a DGLGraph.\")\n",
    "        if 'feat' not in graph.ndata:\n",
    "            raise KeyError(\"Graph must have node features in graph.ndata['feat']\")\n",
    "\n",
    "        x = graph.ndata['feat']  # Node features\n",
    "        x = F.relu(self.gcn1(graph, x))\n",
    "        x = self.gcn2(graph, x)\n",
    "        graph.ndata['h'] = x\n",
    "        return dgl.mean_nodes(graph, 'h')  # Mean pooling for graph-level output\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import dropout_adj\n",
    "\n",
    "from dgl.nn import GraphConv, GATConv\n",
    "\n",
    "class BATCHGAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "        super(BATCHGAT, self).__init__()\n",
    "        \n",
    "        # Graph Convolutional Layers with Batch Normalization\n",
    "        self.gcn1 = GraphConv(in_channels, hidden_channels)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
    "        \n",
    "        self.gcn2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
    "        \n",
    "        # Graph Attention Layer\n",
    "        self.gat1 = GATConv(hidden_channels, hidden_channels, num_heads=8)\n",
    "        \n",
    "        # Final Layer for Output\n",
    "        self.fc = nn.Linear(hidden_channels * 8, out_channels)  # *8 due to multi-head attention\n",
    "        \n",
    "        # Dropout Rate\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, graph, x):\n",
    "        # Apply Graph Convolution with Batch Normalization + Activation + Dropout\n",
    "        x = F.relu(self.bn1(self.gcn1(graph, x)))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Another Graph Convolution Layer\n",
    "        x = F.relu(self.bn2(self.gcn2(graph, x)))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Apply Graph Attention Layer\n",
    "        x = self.gat1(graph, x)\n",
    "        \n",
    "        # Apply Dropout on attention outputs (here's where we handle dropout in the attention heads)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        #x = x.mean(dim=2)\n",
    "        # Final Classification Layer\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1) # Log-Softmax for multi-class classification\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, list_length=250):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.list_length = list_length\n",
    "        self.linear = Linear(input_dim, output_dim * list_length)  # Adjust to correct dimensions\n",
    "\n",
    "    def forward(self, graph_embeddings):\n",
    "        \"\"\"\n",
    "        Decode concatenated graph embeddings into structured outputs.\n",
    "        \"\"\"\n",
    "        batch_size = graph_embeddings.shape[0]\n",
    "        linear_output = self.linear(graph_embeddings)  # Shape: (batch_size, list_length * output_dim)\n",
    "        linear_output = linear_output.view(batch_size, self.list_length, -1)  # Reshape to (batch_size, list_length, output_dim)\n",
    "        return linear_output\n",
    "\n",
    "\n",
    "\n",
    "def process_datapoint(datapoint, model):\n",
    "    \"\"\"\n",
    "    Process a single datapoint from the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - datapoint: A list where:\n",
    "        - datapoint[0] is a 250-length list of 4-element tuples of 4D tensors.\n",
    "        - datapoint[1], datapoint[2], and datapoint[3] are DGL graphs.\n",
    "\n",
    "    Returns:\n",
    "    - target_tensor: Tensor of shape (250, 4).\n",
    "    - batched_graphs: Combined embedding of g1, g2, g3.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Unpack the datapoint\n",
    "        target, g1, g2, g3 = datapoint\n",
    "\n",
    "        # Ensure node features exist for all graphs\n",
    "        for graph in [g1, g2, g3]:\n",
    "            #if 'feat' not in graph.ndata:\n",
    "                #graph.ndata['feat'] = torch.randn(graph.num_nodes(), model.gcn1.in_feats)  # Random features fallback\n",
    "                # Detach node features to ensure no gradient dependencies\n",
    "            graph.ndata['feat'] = graph.ndata['feat'].detach()\n",
    "\n",
    "        # Convert the target (list of 250 tuples) into a tensor of shape (250, 4)\n",
    "        # Each tuple contains four tensors of length 4, so we concatenate them into one tensor\n",
    "        target_tensor = torch.stack(\n",
    "            [torch.cat(tup, dim=0) for tup in target]\n",
    "        ).detach()  # Shape: (250, 4)\n",
    "\n",
    "        # Batch the three graphs into one\n",
    "        batched_graphs = dgl.batch([g1, g2, g3])\n",
    "\n",
    "        return target_tensor, batched_graphs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing datapoint: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model, decoder, optimizer, train_data, val_data, list_length, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        decoder.train()\n",
    "        log=0\n",
    "        train_loss = 0  # Reset train loss for each epoch\n",
    "\n",
    "        # Training loop\n",
    "        for datapoint in tqdm(train_data):\n",
    "            optimizer.zero_grad()  # Reset gradients for each batch\n",
    "\n",
    "            target, batched_graphs = process_datapoint(datapoint, model)\n",
    "\n",
    "            # Forward pass\n",
    "            graph_embeddings = model(batched_graphs,batched_graphs.ndata['feat'])  # Output: (3, 64)\n",
    "            graph_embeddings = graph_embeddings.view(1, -1)  # Reshape to (batch_size, input_dim * 3), e.g., (1, 192)\n",
    "\n",
    "            train_outputs = decoder(graph_embeddings)  # Shape: (batch_size, list_length, 4)\n",
    "\n",
    "            # Prepare predictions and targets\n",
    "            predictions = train_outputs[0]  # Use the first batch (since batch_size=1)\n",
    "            assert predictions.shape == target.shape, f\"Shape mismatch: {predictions.shape} vs {target.shape}\"\n",
    "\n",
    "            # Calculate and backpropagate loss\n",
    "            batch_loss = loss_fn(predictions, target)\n",
    "            batch_loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            train_loss += batch_loss.item()  # Accumulate scalar loss\n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            for datapoint in val_data:\n",
    "                target, batched_graphs = process_datapoint(datapoint, model)\n",
    "                graph_embeddings = model(batched_graphs).view(1, -1)  # Reshape for decoder\n",
    "                val_outputs = decoder(graph_embeddings)\n",
    "\n",
    "                predictions = val_outputs[0]  # Shape: (list_length, 4)\n",
    "                assert predictions.shape == target.shape, f\"Shape mismatch: {predictions.shape} vs {target.shape}\"\n",
    "                val_loss += loss_fn(predictions, target).item()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data, val_ratio=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split a dataset into training and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    - data (list): The dataset to be split (list of datapoints).\n",
    "    - val_ratio (float): Fraction of the data to use as validation (default is 0.2).\n",
    "    - random_state (int): Random seed for reproducibility (default is 42).\n",
    "\n",
    "    Returns:\n",
    "    - train_data (list): Training data split.\n",
    "    - val_data (list): Validation data split.\n",
    "    \"\"\"\n",
    "    train_data, val_data = train_test_split(data, test_size=val_ratio, random_state=random_state)\n",
    "    return train_data, val_data\n",
    "\n",
    "train_data,val_data = split_data(third_filter)\n",
    "learning_rate = 0.001\n",
    "list_length=250\n",
    "num_epochs = 20\n",
    "input_dim = 768\n",
    "hidden_dim=64\n",
    "output_dim=192\n",
    "dropout=0.5\n",
    "#model = GCNEncoder(input_dim=768, hidden_dim=192, output_dim=64)\n",
    "model = BATCHGAT(input_dim, hidden_dim, output_dim,dropout=dropout)\n",
    "decoder = Decoder(input_dim=192, output_dim=16)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(decoder.parameters()), lr=learning_rate)\n",
    "\n",
    "train(model, decoder, optimizer, train_data, val_data, list_length, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Logical Rules\n",
    "All own claim nodes must have a support connection from a data node, this is not true of background claims\n",
    "Acyclic - a node cannot both attack and support the same node at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for (id,sample) in processed_samples.items():\n",
    "    data.append(list(sample.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_graph(x):\n",
    "    return isinstance(x, dgl.DGLGraph)\n",
    "\n",
    "def filter_sample(sample):\n",
    "    [label,g1,g2,g3] = sample\n",
    "    for g in [g1,g2,g3]:\n",
    "        if is_graph(g):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "list(filter(filter_sample,filtered_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
