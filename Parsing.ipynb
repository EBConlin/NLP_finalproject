{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2184fad6-478a-42f5-ae01-2aeeed095f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import spacy\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a058b0c6-d29b-4c42-a08d-13f6f0cd9cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch-geometric) (3.9.5)\n",
      "Requirement already satisfied: fsspec in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch-geometric) (2024.5.0)\n",
      "Requirement already satisfied: jinja2 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch-geometric) (6.0.0)\n",
      "Requirement already satisfied: pyparsing in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch-geometric) (4.66.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from aiohttp->torch-geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests->torch-geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests->torch-geometric) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests->torch-geometric) (2024.7.4)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f804b918-bf8e-4368-965d-d6561fc1eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"UCHAMP , T., AND P OPOVI Ć , Z. 2002. Interactive skeleton-driven dynamic deformations. ACM Transactions on Graphics 21, 3, 586–593. C ATMULL , E. E. 1972. A system for computer generated movies. In Proc. ACM Annual Conf. August, 422–431. F REEMAN , W. T., AND T ENENBAUM , J. B. 1997. Learning bilinear models for two-factor problems in vision. In IEEE Computer Vision and Pattern Recognition. J AMES , D. L., AND P AI , D. K. 2002. DyRT: Dynamic response textures for real time deformation simulation with graphics hardware. ACM Transactions on Graphics 21, 3, 582–585. K RY , P. G., J AMES , D. L., AND P AI , D. K. 2002. Eigenskin: Real time large deformation character skinning in hardware. In ACM SIGGRAPH Symposium on Computer Animation, 153–160. L EWIS , J. P., C ORDNER , M., AND F ONG , N. 2000. Pose space deformations: A unified approach to shape interpolation and skeleton-driven deformation. In Proceedings of ACM SIGGRAPH 2000, Annual Conference Series, ACM SIGGRAPH. M AGNENAT -T HALMANN , N., L APERRIRE , R., AND T HALMANN , D. 1988. Jointdependent local deformations for hand animation and object grasping. In Proceedings of Graphics Interface ’88, 26–33. M ALANDAIN , G., AND B OISSONNAT , J.-D. 2002. Computing the diameter of a point set. In Discrete Geometry for Computer Imagery (DGCI 2002), A. Braquelaire, J.O. Lachaud, and A. Vialard, Eds., vol. 2301. N EBEL , J.-C., AND S IBIRYAKOV , A. 2002. Range flow from\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76cf79e4-4e2e-4dc3-91e6-4531d5428700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import spacy\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from transformers import logging as transformers_logging\n",
    "\n",
    "# Suppress Transformers warnings\n",
    "transformers_logging.set_verbosity_error()\n",
    "\n",
    "#Layer 1: Token level, creates dependency matrix with method --> create_dependency_matrix()\n",
    "\n",
    "def create_dependency_matrix(doc, exclude_tags=[\"punct\"]):\n",
    "    \"\"\"\n",
    "    Create an adjacency matrix based on SpaCy's dependency parsing.\n",
    "\n",
    "    Parameters:\n",
    "        doc (spacy.tokens.Doc): Parsed SpaCy Doc object.\n",
    "        exclude_tags (list): List of dependency tags to exclude.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Adjacency matrix of shape (num_tokens, num_tokens).\n",
    "    \"\"\"\n",
    "    num_tokens = len(doc)\n",
    "    matrix = np.zeros((num_tokens, num_tokens))\n",
    "\n",
    "    for token in doc:\n",
    "        # Only include valid dependencies\n",
    "        if token.dep_ not in exclude_tags and token.head != token:\n",
    "            matrix[token.i, token.head.i] = 1  # token -> head\n",
    "            matrix[token.head.i, token.i] = 1  # head -> token\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "def get_scibert_embeddings(tokens):\n",
    "    \"\"\"\n",
    "    Extract SciBERT embeddings for tokens in the input text.\n",
    "\n",
    "    Parameters:\n",
    "        tokens (list): List of tokens from the input text.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Token embeddings of shape (num_tokens, embedding_dim).\n",
    "        list: List of tokens (aligned with embeddings).\n",
    "    \"\"\"\n",
    "    # Load SciBERT tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "    model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "    # Tokenize using the token list\n",
    "    inputs = tokenizer(\n",
    "        tokens,\n",
    "        is_split_into_words=True,  # Preserve token order\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    # Map subword tokens back to full tokens\n",
    "    word_ids = inputs.word_ids()\n",
    "\n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    subword_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "    # Aggregate subword embeddings to form word-level embeddings\n",
    "    word_embeddings = []\n",
    "    for i in range(len(tokens)):\n",
    "        token_indices = [idx for idx, word_id in enumerate(word_ids) if word_id == i]\n",
    "        if token_indices:\n",
    "            word_embedding = subword_embeddings[token_indices].mean(dim=0)\n",
    "            word_embeddings.append(word_embedding)\n",
    "\n",
    "    word_embeddings = torch.stack(word_embeddings)  # Shape: (num_tokens, embedding_dim)\n",
    "    return word_embeddings, tokens\n",
    "\n",
    "def layer1_output(text,nlp):\n",
    "    \"\"\"\n",
    "    Process text to generate SciBERT embeddings and dependency matrix for Layer 1.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: SciBERT embeddings of shape (num_tokens, embedding_dim).\n",
    "        np.ndarray: Dependency matrix of shape (num_tokens, num_tokens).\n",
    "    \"\"\"\n",
    "    # Step 1: Parse text with SpaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Step 2: Create dependency matrix\n",
    "    dependency_matrix = create_dependency_matrix(doc)\n",
    "\n",
    "    # Step 3: Extract tokens and SciBERT embeddings\n",
    "    tokens = [token.text for token in doc]  # Use SpaCy tokens for consistency\n",
    "    embeddings, scibert_tokens = get_scibert_embeddings(tokens)\n",
    "\n",
    "    # Step 4: Validate alignment\n",
    "    assert tokens == scibert_tokens, \"Token mismatch between SpaCy and SciBERT!\"\n",
    "\n",
    "    return embeddings, dependency_matrix, tokens\n",
    "\n",
    "# # Define Functions\n",
    "# def get_scibert_embeddings(text):\n",
    "#     \"\"\"\n",
    "#     Extract SciBERT embeddings for tokens in the input text.\n",
    "\n",
    "#     Parameters:\n",
    "#         text (str): Input text.\n",
    "\n",
    "#     Returns:\n",
    "#         torch.Tensor: Token embeddings of shape (num_tokens, embedding_dim).\n",
    "#         list: List of tokens from the input text.\n",
    "#     \"\"\"\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "#     model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "#     # Tokenize and encode\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "#     tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     embeddings = outputs.last_hidden_state.squeeze(0)  # Shape: (num_tokens, embedding_dim)\n",
    "\n",
    "#     return embeddings, tokens\n",
    "\n",
    "\n",
    "# def create_dependency_matrix(doc, exclude_tags=[\"punct\"]):\n",
    "#     \"\"\"\n",
    "#     Create an adjacency matrix based on SpaCy's dependency parsing.\n",
    "\n",
    "#     Parameters:\n",
    "#         doc (spacy.tokens.Doc): Parsed SpaCy Doc object.\n",
    "#         exclude_tags (list): List of dependency tags to exclude.\n",
    "\n",
    "#     Returns:\n",
    "#         np.ndarray: Adjacency matrix of shape (num_tokens, num_tokens).\n",
    "#     \"\"\"\n",
    "#     num_tokens = len(doc)\n",
    "#     matrix = np.zeros((num_tokens, num_tokens))\n",
    "\n",
    "#     for token in doc:\n",
    "#         if token.dep_ not in exclude_tags and token.head != token:  # Exclude self-loops and specific tags\n",
    "#             matrix[token.i, token.head.i] = 1  # token -> head\n",
    "#             matrix[token.head.i, token.i] = 1  # head -> token\n",
    "\n",
    "#     return matrix\n",
    "\n",
    "\n",
    "\n",
    "# #NOT USING THIS\n",
    "# def create_similarity_matrix(embeddings, threshold=0.85):\n",
    "#     \"\"\"\n",
    "#     Create an adjacency matrix based on semantic similarity.\n",
    "\n",
    "#     Parameters:\n",
    "#         embeddings (torch.Tensor): Token embeddings of shape (num_tokens, embedding_dim).\n",
    "#         threshold (float): Similarity threshold for creating edges.\n",
    "\n",
    "#     Returns:\n",
    "#         np.ndarray: Adjacency matrix of shape (num_tokens, num_tokens).\n",
    "#     \"\"\"\n",
    "#     from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#     # Convert embeddings to numpy\n",
    "#     embeddings_np = embeddings.detach().cpu().numpy()\n",
    "\n",
    "#     # Compute cosine similarity\n",
    "#     similarity = cosine_similarity(embeddings_np)\n",
    "\n",
    "#     # Threshold to create edges\n",
    "#     matrix = (similarity > threshold).astype(float)\n",
    "#     np.fill_diagonal(matrix, 0)  # Remove self-loops\n",
    "#     return matrix\n",
    "\n",
    "\n",
    "def create_graph_data(embeddings, adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Create a PyTorch Geometric Data object.\n",
    "\n",
    "    Parameters:\n",
    "        embeddings (torch.Tensor): Node features of shape (num_tokens, embedding_dim).\n",
    "        adjacency_matrix (np.ndarray): Adjacency matrix of shape (num_tokens, num_tokens).\n",
    "\n",
    "    Returns:\n",
    "        Data: PyTorch Geometric Data object.\n",
    "    \"\"\"\n",
    "    # Convert adjacency matrix to edge index\n",
    "    edge_index = torch.tensor(np.nonzero(adjacency_matrix), dtype=torch.long)\n",
    "    x = embeddings  # Node features are token embeddings\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "\n",
    "def layer_1(text,nlp):\n",
    "    # Process layer 1\n",
    "    #text = \"\"\"We propose a layered framework for incorporating example-based skinning algorithms such as Pose Space Deformation or Shape-by-Example into an existing character animation system. The challenge in implementing example-based skinning in an existing system lies in the fact that it is generally believed that the interpolation of the examples is best performed before doing other skinning deformations (although there has been no analysis as to why this is the case), whereas the examples are specified by the user after the other deformations are performed. It is therefore necessary to invert the operation of these skinning and deformation operators. Existing systems typically allow layering of both basic skinning methods such as Skeleton Subspace Deformation (SSD) and other deformations such as lattices, etc., and commercial systems may further allow additional proprietary deformation algorithms as part of the character skinning. Unfortunately, understanding and accessing their various parameters can be laborious at best, and we do not have access to the algorithms in the case of commercial packages. The contributions of this paper are 1) a detailed analysis showing how inverting the skinning operations leads to better example interpolation, and 2) a demonstration\"\"\"\n",
    "    assert len(text) > 5, \"Tokens are too short\"\n",
    "    embeddings, dependency_matrix, tokens = layer1_output(text,nlp)\n",
    "\n",
    "\n",
    "    # create graph data\n",
    "    #graph_data = create_graph_data(embeddings, dependency_matrix)\n",
    "    return embeddings, dependency_matrix\n",
    "\n",
    "\n",
    "\n",
    "## TESTING THE DEPENDENCY PARSER - uncomment to text\n",
    "# if __name__ == \"__main__\":\n",
    "#     text = \"The cat sat on the mat.\"\n",
    "#     #text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "#     # Step 1: Parse text with SpaCy\n",
    "#     nlp = spacy.load(\"en_core_web_sm\")\n",
    "#     doc = nlp(text)\n",
    "\n",
    "#     # Step 2: Create the dependency matrix\n",
    "#     dependency_matrix = create_dependency_matrix(doc)\n",
    "\n",
    "#     # Step 3: Extract tokens and SciBERT embeddings\n",
    "#     tokens = [token.text for token in doc]  # All tokens, including punctuation\n",
    "#     embeddings, scibert_tokens = get_scibert_embeddings(tokens)\n",
    "\n",
    "#     for token in doc:\n",
    "#         print(f\"Token: {token.text}, Head: {token.head.text}, Dependency: {token.dep_}, Index: {token.i}, Head Index: {token.head.i}\")\n",
    "\n",
    "#     # Ensure alignment\n",
    "#     assert tokens == scibert_tokens, \"Token mismatch between SpaCy and SciBERT!\"\n",
    "\n",
    "#     # Print results\n",
    "#     print(\"Tokens:\", tokens)\n",
    "#     print(\"Embeddings Shape:\", embeddings.shape)\n",
    "#     print(\"Dependency Matrix:\")\n",
    "#     print(dependency_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e14845-3a29-44f1-ada2-48d01e9439dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer 3:\n",
    "#creates concept-level adjacency matrix with  method -->  layer_3_concept_level()\n",
    "\n",
    "def prioritize_named_entities(text,nlp):\n",
    "    \"\"\"\n",
    "    Extract and prioritize named entities over noun chunks.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        list: Prioritized list of meaningful concepts.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract named entities\n",
    "    named_entities = [ent.text for ent in doc.ents]\n",
    "\n",
    "    # Extract longer noun chunks (e.g., more than two words)\n",
    "    noun_chunks = [chunk.text for chunk in doc.noun_chunks if len(chunk.text.split()) > 2]\n",
    "\n",
    "    # Combine and deduplicate concepts\n",
    "    concepts = list(set(named_entities + noun_chunks))\n",
    "    return concepts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_concept_embeddings(concepts):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of concepts using SciBERT.\n",
    "\n",
    "    Parameters:\n",
    "        concepts (list): List of concepts (strings).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Concept embeddings of shape (num_concepts, embedding_dim).\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "    model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "    concept_embeddings = []\n",
    "    for concept in concepts:\n",
    "        inputs = tokenizer(concept, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token for the concept\n",
    "        concept_embeddings.append(cls_embedding.squeeze(0))\n",
    "\n",
    "    return torch.stack(concept_embeddings)\n",
    "\n",
    "\n",
    "def create_concept_level_matrix(concept_embeddings, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Create adjacency matrix for concept-level relationships.\n",
    "\n",
    "    Parameters:\n",
    "        concept_embeddings (torch.Tensor): Concept embeddings of shape (num_concepts, embedding_dim).\n",
    "        threshold (float): Similarity threshold for connecting concepts.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Adjacency matrix of shape (num_concepts, num_concepts).\n",
    "    \"\"\"\n",
    "    embeddings_np = np.array(concept_embeddings.detach().cpu().tolist())\n",
    "    similarity = cosine_similarity(embeddings_np)\n",
    "\n",
    "    adjacency_matrix = (similarity > threshold).astype(float)\n",
    "    np.fill_diagonal(adjacency_matrix, 0)  # Remove self-loops\n",
    "\n",
    "    # # Dynamically lower threshold if matrix is empty\n",
    "    # if not np.any(adjacency_matrix):\n",
    "    #     print(\"Warning: No connections found. Lowering similarity threshold to 0.7.\")\n",
    "    #     adjacency_matrix = (similarity > 0.75).astype(float)\n",
    "    #     np.fill_diagonal(adjacency_matrix, 0)\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "def add_cooccurrence_edges(concepts, adjacency_matrix, text,nlp):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Build a map of sentences and the concepts they contain\n",
    "    sentence_concepts = {i: [] for i, sent in enumerate(doc.sents)}\n",
    "    for i, sent in enumerate(doc.sents):\n",
    "        for concept in concepts:\n",
    "            if concept in sent.text:\n",
    "                sentence_concepts[i].append(concept)\n",
    "\n",
    "    # Add co-occurrence edges without overwriting existing edges\n",
    "    for sentence, sentence_concept_list in sentence_concepts.items():\n",
    "        for i, concept1 in enumerate(sentence_concept_list):\n",
    "            for concept2 in sentence_concept_list[i + 1:]:\n",
    "                idx1, idx2 = concepts.index(concept1), concepts.index(concept2)\n",
    "                if adjacency_matrix[idx1, idx2] == 0:  # Only add if no existing edge\n",
    "                    adjacency_matrix[idx1, idx2] = 1\n",
    "                    adjacency_matrix[idx2, idx1] = 1  # Bidirectional\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "def layer_3_concept_level(text, nlp, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Process text to generate concept embeddings and adjacency matrix.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): Input text.\n",
    "        threshold (float): Similarity threshold for creating edges.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Concept embeddings of shape (num_concepts, embedding_dim).\n",
    "        np.ndarray: Adjacency matrix of shape (num_concepts, num_concepts).\n",
    "        list: Filtered concepts.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract and prioritize named entities and noun chunks\n",
    "    concepts = prioritize_named_entities(text,nlp)\n",
    "\n",
    "    # Step 2: Filter out generic or irrelevant concepts\n",
    "    # concepts = filter_concepts(concepts)\n",
    "\n",
    "    # Step 3: Generate concept embeddings\n",
    "    concept_embeddings = get_concept_embeddings(concepts)\n",
    "\n",
    "    # Step 4: Create adjacency matrix for semantic similarity\n",
    "    concept_matrix = create_concept_level_matrix(concept_embeddings, threshold=threshold)\n",
    "\n",
    "    # Step 5: Add co-occurrence-based edges\n",
    "    concept_matrix = add_cooccurrence_edges(concepts, concept_matrix, text,nlp)\n",
    "\n",
    "    return concept_embeddings, concept_matrix, concepts\n",
    "\n",
    "\n",
    "#NOTE: the current concept graph is not catching every concept such as \"Shape-by-Example\"\n",
    "def visualize_concept_graph(concepts, matrix):\n",
    "    G = nx.Graph()\n",
    "    for i, concept in enumerate(concepts):\n",
    "        G.add_node(i, label=concept)\n",
    "\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(i + 1, len(matrix)):\n",
    "            if matrix[i, j] > 0:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, labels={i: concepts[i] for i in range(len(concepts))}, node_size=5000, font_size=10)\n",
    "    plt.title(\"Concept-Level Graph\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Input text\n",
    "#     #text = \"\"\"We propose a layered framework for incorporating example-based skinning algorithms such as Pose Space Deformation or Shape-by-Example into an existing character animation system.\"\"\"\n",
    "\n",
    "#     # text = \"\"\"We propose a layered framework for incorporating example-based skinning algorithms such as Pose Space Deformation or Shape-by-Example into an existing character animation system.\n",
    "#     # The challenge in implementing example-based skinning in an existing system lies in the fact that it is generally believed that the interpolation of the examples is best performed before doing other skinning deformations.\"\"\"\n",
    "\n",
    "#     #NOTE: the concept graph is not catching every concept such as \"Shape-by-Example\"\n",
    "#     text = \"\"\"We propose a layered framework for incorporating example-based skinning algorithms such as Pose Space Deformation or Shape-by-Example into an existing character animation system.\n",
    "#     The challenge in implementing example-based skinning in an existing system lies in the fact that it is generally believed that the interpolation of the examples is best performed before doing other skinning deformations.\n",
    "#     It is therefore necessary to invert the operation of these skinning and deformation operators.\"\"\"\n",
    "#     # Process Layer 3\n",
    "#     concept_embeddings, concept_matrix, concepts = layer_3_concept_level(text)\n",
    "\n",
    "#     # Print results\n",
    "#     print(f\"Number of concepts: {len(concepts)}\")\n",
    "#     print(\" Concepts:\", concepts)\n",
    "#     print(\"Concept-Level Adjacency Matrix:\")\n",
    "#     print(concept_matrix)\n",
    "\n",
    "#     # Visualize the graph\n",
    "#     visualize_concept_graph(concepts, concept_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1998a0f-f33f-4b1a-970b-387cdae168bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAYER 2:\n",
    "# Get sentence-level adjacency matrix with method --> layer_2_sentence_level\n",
    "\n",
    "\n",
    "def get_sentences(text,nlp):\n",
    "    \"\"\"\n",
    "    Split text into sentences using SpaCy.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        list: List of sentences.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "#generaate sentence emnbeddings w CLS token from scibert\n",
    "\n",
    "def get_sentence_embeddings(sentences):\n",
    "    \"\"\"\n",
    "    Generate sentence embeddings using the CLS token from SciBERT.\n",
    "\n",
    "    Parameters:\n",
    "        sentences (list): List of sentences.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Sentence embeddings of shape (num_sentences, embedding_dim).\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "    model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        # Tokenize and encode each sentence\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "        # Extract CLS token embedding\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token is at index 0\n",
    "        embeddings.append(cls_embedding.squeeze(0))\n",
    "\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "    #centence-level adjacency matric w/ semtantic similarity between sentences & sequetial edges\n",
    "\n",
    "\n",
    "def create_sentence_level_matrix(sentence_embeddings, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Create an adjacency matrix for sentence-level relationships.\n",
    "\n",
    "    Parameters:\n",
    "        sentence_embeddings (torch.Tensor): Sentence embeddings of shape (num_sentences, embedding_dim).\n",
    "        threshold (float): Similarity threshold for connecting sentences.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Adjacency matrix of shape (num_sentences, num_sentences).\n",
    "    \"\"\"\n",
    "\n",
    "    #DIDNT WORK ON MY SYSTEM: change to this if works on yours\n",
    "    #embeddings_np = sentence_embeddings.detach().cpu().numpy()\n",
    "    #COMMENT LINE BELOW IF THE ABOVE WORKS\n",
    "    embeddings_np = np.array(sentence_embeddings.detach().cpu().tolist())\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(embeddings_np)\n",
    "\n",
    "    # Create adjacency matrix based on similarity\n",
    "    adjacency_matrix = (similarity > threshold).astype(float)\n",
    "\n",
    "    # Add sequential connections\n",
    "    num_sentences = embeddings_np.shape[0]\n",
    "    for i in range(num_sentences - 1):\n",
    "        adjacency_matrix[i, i + 1] = 1\n",
    "        adjacency_matrix[i + 1, i] = 1\n",
    "\n",
    "    np.fill_diagonal(adjacency_matrix, 0)  # Remove self-loops\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "\n",
    "    #combine\n",
    "def layer_2_sentence_level(text,nlp):\n",
    "    \"\"\"\n",
    "    Process text to generate sentence embeddings and adjacency matrix.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Sentence embeddings of shape (num_sentences, embedding_dim).\n",
    "        np.ndarray: Adjacency matrix of shape (num_sentences, num_sentences).\n",
    "    \"\"\"\n",
    "    # Step 1: Tokenize text into sentences\n",
    "    sentences = get_sentences(text,nlp)\n",
    "\n",
    "    # Step 2: Generate sentence embeddings\n",
    "    sentence_embeddings = get_sentence_embeddings(sentences)\n",
    "\n",
    "    # Step 3: Create sentence-level adjacency matrix\n",
    "    sentence_matrix = create_sentence_level_matrix(sentence_embeddings)\n",
    "\n",
    "    masked_results = []\n",
    "    for mask in range(len(sentences)):\n",
    "        try:\n",
    "            embedding = sentence_embeddings[mask,:]\n",
    "            remaining_embeddings = torch.cat((sentence_embeddings[:mask,:], sentence_embeddings[mask+1:,:]), dim=0)\n",
    "            #print(embedding)\n",
    "\n",
    "            sentence = sentences[mask]\n",
    "            assert len(sentence) > 0, \"torch is too small\"\n",
    "        \n",
    "            masked_sentence_matrix = create_sentence_level_matrix(remaining_embeddings)\n",
    "\n",
    "            masked_results.append([[remaining_embeddings,masked_sentence_matrix],[sentence, embedding]])\n",
    "        except Exception as e:\n",
    "            print(f\"lost mask {e}\")\n",
    "\n",
    "    return sentence_embeddings, sentence_matrix, masked_results\n",
    "\n",
    "\n",
    "# #TESTING\n",
    "# if __name__ == \"__main__\":\n",
    "#     #First three sentences of the abstract\n",
    "#     text = \"\"\"We propose a layered framework for incorporating example-based skinning algorithms such as Pose Space Deformation or Shape-by-Example into an existing character animation system.\n",
    "#     The challenge in implementing example-based skinning in an existing system lies in the fact that it is generally believed that the interpolation of the examples is best performed before doing other skinning deformations.\n",
    "#     It is therefore necessary to invert the operation of these skinning and deformation operators.\"\"\"\n",
    "\n",
    "#     sentence_embeddings, sentence_matrix = layer_2_sentence_level(text)\n",
    "\n",
    "#     print(f\"Number of sentences: {sentence_embeddings.shape[0]}\")\n",
    "#     print(\"Sentence-Level Adjacency Matrix:\")\n",
    "#     print(sentence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b339fbdc-2b92-48f3-831e-04d4f1cf5cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [23:25<00:00, 35.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed. Results saved to pickle files: [('A01', 'data_2/results_A01.pkl'), ('A02', 'data_2/results_A02.pkl'), ('A03', 'data_2/results_A03.pkl'), ('A04', 'data_2/results_A04.pkl'), ('A05', 'data_2/results_A05.pkl'), ('A06', 'data_2/results_A06.pkl'), ('A07', 'data_2/results_A07.pkl'), ('A08', 'data_2/results_A08.pkl'), ('A09', 'data_2/results_A09.pkl'), ('A10', 'data_2/results_A10.pkl'), ('A11', 'data_2/results_A11.pkl'), ('A12', 'data_2/results_A12.pkl'), ('A13', 'data_2/results_A13.pkl'), ('A14', 'data_2/results_A14.pkl'), ('A15', 'data_2/results_A15.pkl'), ('A16', 'data_2/results_A16.pkl'), ('A17', 'data_2/results_A17.pkl'), ('A18', 'data_2/results_A18.pkl'), ('A19', 'data_2/results_A19.pkl'), ('A20', 'data_2/results_A20.pkl'), ('A21', 'data_2/results_A21.pkl'), ('A22', 'data_2/results_A22.pkl'), ('A23', 'data_2/results_A23.pkl'), ('A24', 'data_2/results_A24.pkl'), ('A25', 'data_2/results_A25.pkl'), ('A26', 'data_2/results_A26.pkl'), ('A27', 'data_2/results_A27.pkl'), ('A28', 'data_2/results_A28.pkl'), ('A29', 'data_2/results_A29.pkl'), ('A30', 'data_2/results_A30.pkl'), ('A31', 'data_2/results_A31.pkl'), ('A32', 'data_2/results_A32.pkl'), ('A33', 'data_2/results_A33.pkl'), ('A34', 'data_2/results_A34.pkl'), ('A35', 'data_2/results_A35.pkl'), ('A36', 'data_2/results_A36.pkl'), ('A37', 'data_2/results_A37.pkl'), ('A38', 'data_2/results_A38.pkl'), ('A39', 'data_2/results_A39.pkl'), ('A40', 'data_2/results_A40.pkl')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "# Load SpaCy model globally\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load clean_data\n",
    "with open(\"clean_data_list.pkl\", \"rb\") as f:\n",
    "    clean_data = pickle.load(f)\n",
    "\n",
    "# Function to process a single sample\n",
    "def process_sample(sample):\n",
    "    \"\"\"\n",
    "    Process a single sample sequentially.\n",
    "    Args:\n",
    "        sample (list): A list containing [text, label].\n",
    "\n",
    "    Returns:\n",
    "        list: Processed sample with additional layers.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = sample[0]\n",
    "        label = sample[1]\n",
    "\n",
    "        # Perform Layer 1, Layer 2, and Layer 3 processing (sequential)\n",
    "        word_level = layer_1(text, nlp)\n",
    "        sentence_level = layer_2_sentence_level(text, nlp)\n",
    "        concept_level = layer_3_concept_level(text, nlp)\n",
    "\n",
    "        # Construct result dictionary\n",
    "        layer_dict = {\n",
    "            \"layer_1\": word_level,\n",
    "            \"layer_2\": sentence_level,\n",
    "            \"layer_3\": concept_level,\n",
    "        }\n",
    "        return [text, label, layer_dict]\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"sample\": sample}\n",
    "\n",
    "# Process all samples for a single ID\n",
    "def process_samples_for_id(id_samples):\n",
    "    \"\"\"\n",
    "    Process all samples for a given ID sequentially.\n",
    "    Args:\n",
    "        id_samples (tuple): A tuple containing (ID, list of samples).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ID, results for all samples).\n",
    "    \"\"\"\n",
    "    id, samples = id_samples\n",
    "    results = []\n",
    "\n",
    "    # Process samples in parallel\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(process_sample, samples))\n",
    "\n",
    "    # Save results for the ID to a pickle file\n",
    "    results_dir = \"data_2\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    save_path = os.path.join(results_dir, f\"results_{id}.pkl\")\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    return id, save_path\n",
    "\n",
    "# Parallelize processing across IDs\n",
    "def parallel_process_ids(clean_data, max_workers=2):\n",
    "    \"\"\"\n",
    "    Processes all IDs in parallel.\n",
    "\n",
    "    Args:\n",
    "        clean_data (dict): Dictionary of ID -> list of samples.\n",
    "        max_workers (int): Number of parallel workers.\n",
    "\n",
    "    Returns:\n",
    "        list: List of processed IDs with their corresponding pickle paths.\n",
    "    \"\"\"\n",
    "    id_sample_pairs = list(clean_data.items())\n",
    "    processed_ids = []\n",
    "\n",
    "    # Process IDs in parallel\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for id, save_path in tqdm(executor.map(process_samples_for_id, id_sample_pairs), total=len(id_sample_pairs)):\n",
    "            processed_ids.append((id, save_path))\n",
    "\n",
    "    return processed_ids\n",
    "\n",
    "# Run the processing\n",
    "if __name__ == \"__main__\":\n",
    "    processed_ids = parallel_process_ids(clean_data)\n",
    "    print(f\"Processing completed. Results saved to pickle files: {processed_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf7c345-27b0-42e7-b680-59d877018abf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'nested_defaultdict' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load clean_data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabeled_directory.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     clean_data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/dill/_dill.py:289\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, ignore, **kwds)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(file, ignore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    284\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    Unpickle an object from a file.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    See :func:`loads` for keyword arguments.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnpickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/dill/_dill.py:444\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mStockUnpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_main_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore:\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# point obj class to main\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/dill/_dill.py:434\u001b[0m, in \u001b[0;36mUnpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m#XXX: special case: NoneType missing\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdill.dill\u001b[39m\u001b[38;5;124m'\u001b[39m: module \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdill._dill\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStockUnpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'nested_defaultdict' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# Load clean_data\n",
    "\n",
    "with open(\"labeled_directory.pkl\", \"rb\") as f:\n",
    "    clean_data = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b05bdf4-ef41-4bea-ac69-349832d92501",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'nested_defaultdict' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabeled_directory.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     clean_data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'nested_defaultdict' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"labeled_directory.pkl\", \"rb\") as f:\n",
    "    clean_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4199937c-4e50-4a73-82fe-57c45aba3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6f3dd0-fe25-4ddc-a64c-10a94fbb9643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n . \\uf8ee \\uf8ef \\uf8f0 (T (T 2,e 2,e 1 k − − . . . T T 1,e 1,e k 1 )v )v d d ··· ··· .. . (T (T n,e n,e 1 k − − . . . T T 1,e 1,e k 1 )v )v d d \\uf8f9 \\uf8fb \\uf8fa \\uf8f0 \\uf8ee \\uf8ef \\uf8ef w w w . . . 2 n 3 \\uf8fa \\uf8fb \\uf8fa \\uf8f9 = \\uf8ef \\uf8f0 \\uf8ee v v e e 1 k − − T T . . . 1,e 1,e 1 k v v d d \\uf8f9 \\uf8fa \\uf8fb 5 To appear at SIGGRAPH 2003 The matrix used to solve for vertex positions is as follows. \\uf8ee \\uf8f0 \\uf8ef ∑ ∑ i=1 n i=1 n w w . . . i i T T i,e i,e 1 k \\uf8f9 \\uf8fa \\uf8fb v d = \\uf8f0 \\uf8ef \\uf8ee v v . . . e e 1 k \\uf8fa \\uf8fb \\uf8f9 To handle homogeneous coordinates, the translation parts of the ∑ i=1 n w i T i,e k matrices are subtracted from the v e on the right hand side. We solve these least-squares problems using the singular value decomposition. This lets us detect when our matrices are rank deficient, leading to overfitting. We detect this by comparing the ratio of the largest singular value to the smallest, and issuing a warning if there are any singular values below some fraction of this ratio. To recover, we zero these singular values and',\n",
       " [('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('T319', 'B-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T319', 'I-own_claim', 0),\n",
       "  ('T317', 'B-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('T317', 'I-own_claim', 0),\n",
       "  ('', '', ''),\n",
       "  ('T318', 'B-own_claim', 0),\n",
       "  ('T318', 'I-own_claim', 0),\n",
       "  ('T318', 'I-own_claim', 0),\n",
       "  ('', '', ''),\n",
       "  ('T316', 'B-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('T316', 'I-data', ('supports', 'T318')),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', ''),\n",
       "  ('', '', '')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"clean_data_list.pkl\",\"rb\") as f:\n",
    "    x = pickle.load(f)\n",
    "\n",
    "x[\"A05\"][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "142952cf-dec3-4cf5-9d17-775c594a3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09558f-6290-413a-91dc-6b7d76e4bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Example function with error handling\n",
    "def process_sample(sample):\n",
    "    try:\n",
    "        text = sample[0]\n",
    "        word_level = layer_1(text,nlp)\n",
    "        #(l2_embeddings,l2_matrix,l2_masks) = layer_2_sentence_level(text)\n",
    "        #concept_level = layer_3_concept_level(text)\n",
    "        sample.append({'layer_1': word_level\n",
    "        #'layer_2': (l2_embeddings,l2_matrix),\n",
    "        #'layer_3': concept_level,\n",
    "        #'masks': l2_masks\n",
    "        })\n",
    "        return  sample\n",
    "    except Exception as e:\n",
    "        pprint(f\"Error processing sample {e}\")\n",
    "        return None  # Or handle as needed\n",
    "\n",
    "# Parallelize the processing using ProcessPoolExecutor\n",
    "\n",
    "DATA_DIR = \"./data/\"\n",
    "remaining_keys = list(clean_data.keys())\n",
    "for id in tqdm(remaining_keys):\n",
    "  samples = clean_data[id]\n",
    "  with ProcessPoolExecutor() as executor:\n",
    "      results = list(tqdm(executor.map(process_sample, samples), total=len(samples)))\n",
    "  with open(DATA_DIR + str(id)+\"layer1.pkl\",\"wb\") as paper:\n",
    "    pickle.dump(results,paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6815f81-4533-4860-a55c-dd7b07e41f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 10%|█         | 4/40 [05:07<46:04, 76.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 71\u001b[0m, in \u001b[0;36mparallel_process_ids\u001b[0;34m(clean_data, max_workers)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Parallelize the processing of IDs\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_sample_pairs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mid_sample_pairs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessed_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/concurrent/futures/process.py:620\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03mSpecialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03mEach item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03mcareful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 78\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Run the processing\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 78\u001b[0m     processed_ids \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_process_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing completed. Results saved to pickle files: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessed_ids\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 69\u001b[0m, in \u001b[0;36mparallel_process_ids\u001b[0;34m(clean_data, max_workers)\u001b[0m\n\u001b[1;32m     66\u001b[0m id_sample_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(clean_data\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m     67\u001b[0m processed_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 69\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mProcessPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Parallelize the processing of IDs\u001b[39;49;00m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_sample_pairs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mid_sample_pairs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessed_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/concurrent/futures/process.py:851\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread_wakeup\u001b[38;5;241m.\u001b[39mwakeup()\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m wait:\n\u001b[0;32m--> 851\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor_manager_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# objects that use file descriptors.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "# Load SpaCy model globally\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load clean_data\n",
    "with open(\"clean_data_list.pkl\", \"rb\") as f:\n",
    "    clean_data = pickle.load(f)\n",
    "\n",
    "# Function to process a single sample\n",
    "def process_sample(sample):\n",
    "    try:\n",
    "        text = sample[0]\n",
    "        label = sample[1]\n",
    "\n",
    "        # Perform Layer 1 processing (sequentially)\n",
    "        word_level = layer_1(text, nlp)\n",
    "\n",
    "        # Construct result dictionary\n",
    "        layer_dict = {'layer_1': word_level}\n",
    "        return [text, label, layer_dict]\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"sample\": sample}\n",
    "\n",
    "# Process all samples for a single ID\n",
    "def process_id(id_samples):\n",
    "    \"\"\"\n",
    "    Process all samples for a given ID.\n",
    "    Args:\n",
    "        id_samples (tuple): A tuple containing (ID, list of samples).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ID, results for all samples).\n",
    "    \"\"\"\n",
    "    id, samples = id_samples\n",
    "    results = []\n",
    "\n",
    "    # Process each sample sequentially (inner operations are sequential)\n",
    "    for sample in samples:\n",
    "        result = process_sample(sample)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "\n",
    "    # Save results for the ID to a pickle file\n",
    "    save_path = f\"results_{id}.pkl\"\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    return id, save_path\n",
    "\n",
    "# Parallelize processing across IDs\n",
    "def parallel_process_ids(clean_data, max_workers=2):\n",
    "    \"\"\"\n",
    "    Process all IDs in parallel.\n",
    "    Args:\n",
    "        clean_data (dict): Dictionary of ID -> list of samples.\n",
    "        max_workers (int): Number of parallel workers.\n",
    "\n",
    "    Returns:\n",
    "        list: List of processed IDs with their corresponding pickle paths.\n",
    "    \"\"\"\n",
    "    id_sample_pairs = list(clean_data.items())\n",
    "    processed_ids = []\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Parallelize the processing of IDs\n",
    "        for id, save_path in tqdm(executor.map(process_id, id_sample_pairs), total=len(id_sample_pairs)):\n",
    "            processed_ids.append((id, save_path))\n",
    "\n",
    "    return processed_ids\n",
    "\n",
    "# Run the processing\n",
    "if __name__ == \"__main__\":\n",
    "    processed_ids = parallel_process_ids(clean_data)\n",
    "    print(f\"Processing completed. Results saved to pickle files: {processed_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48415fb4-e6cd-49a0-8ca1-ce2d1cd482f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/24 [00:03<01:24,  3.69s/it]\u001b[A\n",
      "  8%|▊         | 2/24 [00:07<01:21,  3.71s/it]\u001b[A\n",
      " 12%|█▎        | 3/24 [00:10<01:16,  3.63s/it]\u001b[A\n",
      " 17%|█▋        | 4/24 [00:14<01:11,  3.59s/it]\u001b[A\n",
      " 21%|██        | 5/24 [00:17<01:07,  3.55s/it]\u001b[A\n",
      " 25%|██▌       | 6/24 [00:21<01:04,  3.57s/it]\u001b[A\n",
      " 29%|██▉       | 7/24 [00:25<01:01,  3.62s/it]\u001b[A\n",
      " 33%|███▎      | 8/24 [00:28<00:57,  3.60s/it]\u001b[A\n",
      " 38%|███▊      | 9/24 [00:32<00:53,  3.56s/it]\u001b[A\n",
      " 42%|████▏     | 10/24 [00:35<00:49,  3.55s/it]\u001b[A\n",
      " 46%|████▌     | 11/24 [00:39<00:45,  3.51s/it]\u001b[A\n",
      " 50%|█████     | 12/24 [00:42<00:41,  3.49s/it]\u001b[A\n",
      " 54%|█████▍    | 13/24 [00:46<00:38,  3.54s/it]\u001b[A\n",
      " 58%|█████▊    | 14/24 [00:49<00:35,  3.55s/it]\u001b[A\n",
      " 62%|██████▎   | 15/24 [00:53<00:31,  3.53s/it]\u001b[A\n",
      " 67%|██████▋   | 16/24 [00:56<00:28,  3.53s/it]\u001b[A\n",
      " 71%|███████   | 17/24 [01:00<00:24,  3.54s/it]\u001b[A\n",
      " 75%|███████▌  | 18/24 [01:04<00:21,  3.57s/it]\u001b[A\n",
      " 79%|███████▉  | 19/24 [01:07<00:17,  3.58s/it]\u001b[A\n",
      " 83%|████████▎ | 20/24 [01:11<00:14,  3.55s/it]\u001b[A\n",
      " 88%|████████▊ | 21/24 [01:14<00:10,  3.57s/it]\u001b[A\n",
      " 92%|█████████▏| 22/24 [01:19<00:07,  3.94s/it]\u001b[A\n",
      " 96%|█████████▌| 23/24 [01:24<00:04,  4.19s/it]\u001b[A\n",
      "100%|██████████| 24/24 [01:25<00:00,  3.57s/it]\u001b[A\n",
      "  2%|▎         | 1/40 [01:25<55:43, 85.72s/it]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/30 [00:03<01:51,  3.84s/it]\u001b[A\n",
      "  7%|▋         | 2/30 [00:07<01:48,  3.89s/it]\u001b[A\n",
      " 10%|█         | 3/30 [00:11<01:42,  3.80s/it]\u001b[A\n",
      " 13%|█▎        | 4/30 [00:15<01:38,  3.80s/it]\u001b[A\n",
      " 17%|█▋        | 5/30 [00:18<01:33,  3.76s/it]\u001b[A\n",
      " 20%|██        | 6/30 [00:22<01:27,  3.67s/it]\u001b[A\n",
      " 23%|██▎       | 7/30 [00:25<01:23,  3.61s/it]\u001b[A\n",
      " 27%|██▋       | 8/30 [00:29<01:19,  3.59s/it]\u001b[A\n",
      " 30%|███       | 9/30 [00:33<01:17,  3.67s/it]\u001b[A\n",
      " 33%|███▎      | 10/30 [00:36<01:11,  3.58s/it]\u001b[A\n",
      " 37%|███▋      | 11/30 [00:40<01:06,  3.49s/it]\u001b[A\n",
      " 40%|████      | 12/30 [00:43<01:01,  3.44s/it]\u001b[A\n",
      " 43%|████▎     | 13/30 [00:46<00:58,  3.46s/it]\u001b[A\n",
      " 47%|████▋     | 14/30 [00:50<00:56,  3.52s/it]\u001b[A\n",
      " 50%|█████     | 15/30 [00:54<00:56,  3.73s/it]\u001b[A\n",
      " 53%|█████▎    | 16/30 [00:58<00:52,  3.77s/it]\u001b[A\n",
      " 57%|█████▋    | 17/30 [01:02<00:49,  3.78s/it]\u001b[A\n",
      " 60%|██████    | 18/30 [01:05<00:44,  3.73s/it]\u001b[A\n",
      " 63%|██████▎   | 19/30 [01:09<00:39,  3.63s/it]\u001b[A\n",
      " 67%|██████▋   | 20/30 [01:15<00:37,  3.79s/it]\u001b[A\n",
      "  2%|▎         | 1/40 [02:41<1:44:58, 161.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m tqdm(samples):\n\u001b[0;32m---> 40\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mprocess_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     41\u001b[0m test_results[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m results\n",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36mprocess_samples\u001b[0;34m(sample, nlp)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_samples\u001b[39m(sample,nlp\u001b[38;5;241m=\u001b[39mnlp):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     text \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m     word_level \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#(l2_embeddings,l2_matrix,l2_masks) = layer_2_sentence_level(text,nlp)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#concept_level = layer_3_concept_level(text,nlp)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     layer_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_1\u001b[39m\u001b[38;5;124m'\u001b[39m: word_level}\n",
      "Cell \u001b[0;32mIn[14], line 199\u001b[0m, in \u001b[0;36mlayer_1\u001b[0;34m(text, nlp)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlayer_1\u001b[39m(text,nlp):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# Process layer 1\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m#text = \"\"\"We propose a layered framework for incorporating example-based skinning algorithms such as Pose Space Deformation or Shape-by-Example into an existing character animation system. The challenge in implementing example-based skinning in an existing system lies in the fact that it is generally believed that the interpolation of the examples is best performed before doing other skinning deformations (although there has been no analysis as to why this is the case), whereas the examples are specified by the user after the other deformations are performed. It is therefore necessary to invert the operation of these skinning and deformation operators. Existing systems typically allow layering of both basic skinning methods such as Skeleton Subspace Deformation (SSD) and other deformations such as lattices, etc., and commercial systems may further allow additional proprietary deformation algorithms as part of the character skinning. Unfortunately, understanding and accessing their various parameters can be laborious at best, and we do not have access to the algorithms in the case of commercial packages. The contributions of this paper are 1) a detailed analysis showing how inverting the skinning operations leads to better example interpolation, and 2) a demonstration\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     embeddings, dependency_matrix, tokens \u001b[38;5;241m=\u001b[39m \u001b[43mlayer1_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m# create graph data\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m#graph_data = create_graph_data(embeddings, dependency_matrix)\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings, dependency_matrix\n",
      "Cell \u001b[0;32mIn[14], line 97\u001b[0m, in \u001b[0;36mlayer1_output\u001b[0;34m(text, nlp)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Step 3: Extract tokens and SciBERT embeddings\u001b[39;00m\n\u001b[1;32m     96\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc]  \u001b[38;5;66;03m# Use SpaCy tokens for consistency\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m embeddings, scibert_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mget_scibert_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Step 4: Validate alignment\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m tokens \u001b[38;5;241m==\u001b[39m scibert_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken mismatch between SpaCy and SciBERT!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[14], line 64\u001b[0m, in \u001b[0;36mget_scibert_embeddings\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Get embeddings\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 64\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m subword_embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Aggregate subword embeddings to form word-level embeddings\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 551\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "\n",
    "with open(\"clean_data_list.pkl\",\"rb\") as f:\n",
    "      clean_data = pickle.load(f)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Example function with error handling\n",
    "def process_samples(sample,nlp=nlp):\n",
    "    #try:\n",
    "    text = sample[0]\n",
    "    word_level = layer_1(text, nlp)\n",
    "    #(l2_embeddings,l2_matrix,l2_masks) = layer_2_sentence_level(text,nlp)\n",
    "    #concept_level = layer_3_concept_level(text,nlp)\n",
    "    layer_dict = {'layer_1': word_level}\n",
    "    #'layer_2': (l2_embeddings,l2_matrix),\n",
    "    #'layer_3': concept_level}\n",
    "        #'masks': l2_masks\n",
    "    return [sample[0],sample[1],layer_dict]\n",
    "        #except Exception as e:\n",
    "            #print(f\"Problem loading sample {e}\")\n",
    "    \n",
    "# Parallelize the processing using ProcessPoolExecutor\n",
    "\n",
    "        \n",
    "\n",
    "from collections import defaultdict\n",
    "test_results = defaultdict(list)\n",
    "for id in tqdm(clean_data.keys()):\n",
    "     samples = clean_data[id]\n",
    "     results = []\n",
    "     for sample in tqdm(samples):\n",
    "         results.append(process_samples(sample))\n",
    "     test_results[id] = results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7af681f-3548-47c5-bc0d-1e9fc514000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_2/results_A01.pkl\",\"rb\") as f:\n",
    "      test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb457b1c-834e-4a14-a943-d65e5c6ecab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7c4dd-af25-48cb-bd0d-0937db09f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "\n",
    "with open(\"clean_data_list.pkl\",\"rb\") as f:\n",
    "      clean_data = pickle.load(f)\n",
    "\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Example function with error handling\n",
    "def process_samples(samples,nlp=nlp):\n",
    "    new_samples = []\n",
    "    for sample in samples:\n",
    "    #try:\n",
    "        text = sample[0]\n",
    "        word_level = layer_1(text,nlp)\n",
    "        (l2_embeddings,l2_matrix,l2_masks) = layer_2_sentence_level(text,nlp)\n",
    "        concept_level = layer_3_concept_level(text,nlp)\n",
    "        layer_dict = {'layer_1': word_level\n",
    "        #'layer_2': (l2_embeddings,l2_matrix),\n",
    "        #'layer_3': concept_level}\n",
    "            #'masks': l2_masks\n",
    "        new_samples.append([sample[0],sample[1],layers])\n",
    "    return new_samples\n",
    "        #except Exception as e:\n",
    "            #print(f\"Problem loading sample {e}\")\n",
    "    \n",
    "# Parallelize the processing using ProcessPoolExecutor\n",
    "\n",
    "from collections import defaultdict\n",
    "test_results = defaultdict(list)\n",
    "for id in tqdm(clean_data.keys()):\n",
    "     samples = clean_data[id]\n",
    "     results = []\n",
    "     with ProcessPoolExecutor() as executor:\n",
    "        results.append(list(tqdm(executor.map(process_samples, samples), total=len(samples))))\n",
    "     test_results[id] = results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd1581be-c389-4fd5-b272-7ed4a7355f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/24 [00:04<01:54,  4.97s/it]\u001b[A\n",
      " 71%|███████   | 17/24 [00:08<00:03,  2.30it/s]\u001b[A\n",
      " 83%|████████▎ | 20/24 [00:09<00:01,  2.54it/s]\u001b[A\n",
      " 92%|█████████▏| 22/24 [00:10<00:00,  2.54it/s]\u001b[A\n",
      "100%|██████████| 24/24 [00:10<00:00,  2.30it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:11<07:21, 11.33s/it]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/30 [00:04<02:21,  4.87s/it]\u001b[A\n",
      "  7%|▋         | 2/30 [00:05<00:58,  2.09s/it]\u001b[A\n",
      " 50%|█████     | 15/30 [00:05<00:03,  4.81it/s]\u001b[A\n",
      " 57%|█████▋    | 17/30 [00:09<00:06,  2.11it/s]\u001b[A\n",
      " 60%|██████    | 18/30 [00:09<00:05,  2.27it/s]\u001b[A\n",
      " 67%|██████▋   | 20/30 [00:09<00:03,  2.81it/s]\u001b[A\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.84it/s]\u001b[A\n",
      "  5%|▌         | 2/40 [00:22<07:12, 11.38s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/32 [00:05<02:36,  5.06s/it]\u001b[A\n",
      " 12%|█▎        | 4/32 [00:05<00:27,  1.01it/s]\u001b[A\n",
      " 53%|█████▎    | 17/32 [00:08<00:05,  2.53it/s]\u001b[A\n",
      " 56%|█████▋    | 18/32 [00:09<00:05,  2.43it/s]\u001b[A\n",
      " 72%|███████▏  | 23/32 [00:09<00:02,  3.68it/s]\u001b[A\n",
      " 78%|███████▊  | 25/32 [00:09<00:01,  4.10it/s]\u001b[A\n",
      " 84%|████████▍ | 27/32 [00:10<00:01,  3.99it/s]\u001b[A\n",
      "100%|██████████| 32/32 [00:11<00:00,  2.73it/s]\u001b[A\n",
      "  8%|▊         | 3/40 [00:35<07:21, 11.92s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/25 [00:05<02:02,  5.09s/it]\u001b[A\n",
      " 16%|█▌        | 4/25 [00:07<00:31,  1.52s/it]\u001b[A\n",
      " 28%|██▊       | 7/25 [00:07<00:13,  1.35it/s]\u001b[A\n",
      " 68%|██████▊   | 17/25 [00:08<00:02,  3.33it/s]\u001b[A\n",
      " 72%|███████▏  | 18/25 [00:11<00:03,  1.99it/s]\u001b[A\n",
      "100%|██████████| 25/25 [00:11<00:00,  2.14it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:47<07:17, 12.15s/it]\n",
      "  0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/29 [00:04<02:07,  4.57s/it]\u001b[A\n",
      "  7%|▋         | 2/29 [00:04<00:55,  2.07s/it]\u001b[A\n",
      " 59%|█████▊    | 17/29 [00:08<00:04,  2.65it/s]\u001b[A\n",
      " 69%|██████▉   | 20/29 [00:09<00:03,  2.79it/s]\u001b[A\n",
      " 83%|████████▎ | 24/29 [00:09<00:01,  3.77it/s]\u001b[A\n",
      " 90%|████████▉ | 26/29 [00:09<00:00,  4.26it/s]\u001b[A\n",
      "100%|██████████| 29/29 [00:10<00:00,  2.76it/s]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:59<06:55, 11.86s/it]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/33 [00:05<02:48,  5.26s/it]\u001b[A\n",
      "  6%|▌         | 2/33 [00:05<01:14,  2.41s/it]\u001b[A\n",
      " 52%|█████▏    | 17/33 [00:09<00:06,  2.37it/s]\u001b[A\n",
      " 70%|██████▉   | 23/33 [00:09<00:02,  3.37it/s]\u001b[A\n",
      " 73%|███████▎  | 24/33 [00:10<00:02,  3.48it/s]\u001b[A\n",
      " 88%|████████▊ | 29/33 [00:10<00:00,  4.41it/s]\u001b[A\n",
      "100%|██████████| 33/33 [00:12<00:00,  2.66it/s]\u001b[A\n",
      " 15%|█▌        | 6/40 [01:12<06:59, 12.33s/it]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/24 [00:04<01:52,  4.89s/it]\u001b[A\n",
      " 17%|█▋        | 4/24 [00:07<00:30,  1.54s/it]\u001b[A\n",
      " 42%|████▏     | 10/24 [00:07<00:06,  2.10it/s]\u001b[A\n",
      " 71%|███████   | 17/24 [00:11<00:03,  1.76it/s]\u001b[A\n",
      "100%|██████████| 24/24 [00:12<00:00,  1.93it/s]\u001b[A\n",
      " 18%|█▊        | 7/40 [01:25<06:58, 12.67s/it]\n",
      "  0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/29 [00:04<02:19,  4.98s/it]\u001b[A\n",
      " 59%|█████▊    | 17/29 [00:08<00:05,  2.36it/s]\u001b[A\n",
      " 62%|██████▏   | 18/29 [00:09<00:04,  2.31it/s]\u001b[A\n",
      " 79%|███████▉  | 23/29 [00:09<00:01,  3.50it/s]\u001b[A\n",
      " 86%|████████▌ | 25/29 [00:09<00:01,  3.78it/s]\u001b[A\n",
      "100%|██████████| 29/29 [00:11<00:00,  2.56it/s]\u001b[A\n",
      " 20%|██        | 8/40 [01:37<06:40, 12.52s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/22 [00:05<01:49,  5.21s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [00:05<00:19,  1.08s/it]\u001b[A\n",
      " 77%|███████▋  | 17/22 [00:09<00:02,  2.48it/s]\u001b[A\n",
      " 82%|████████▏ | 18/22 [00:09<00:01,  2.46it/s]\u001b[A\n",
      "100%|██████████| 22/22 [00:10<00:00,  2.11it/s]\u001b[A\n",
      " 22%|██▎       | 9/40 [01:49<06:16, 12.14s/it]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▎         | 1/27 [00:05<02:25,  5.60s/it]\u001b[A\n",
      " 63%|██████▎   | 17/27 [00:10<00:05,  1.84it/s]\u001b[A\n",
      " 89%|████████▉ | 24/27 [00:11<00:01,  2.81it/s]\u001b[A\n",
      "100%|██████████| 27/27 [00:11<00:00,  2.33it/s]\u001b[A\n",
      " 25%|██▌       | 10/40 [02:01<06:07, 12.25s/it]\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/37 [00:05<03:12,  5.34s/it]\u001b[A\n",
      " 46%|████▌     | 17/37 [00:09<00:09,  2.08it/s]\u001b[A\n",
      " 51%|█████▏    | 19/37 [00:09<00:07,  2.32it/s]\u001b[A\n",
      " 54%|█████▍    | 20/37 [00:10<00:07,  2.35it/s]\u001b[A\n",
      " 57%|█████▋    | 21/37 [00:11<00:07,  2.09it/s]\u001b[A\n",
      " 89%|████████▉ | 33/37 [00:13<00:01,  3.64it/s]\u001b[A\n",
      " 92%|█████████▏| 34/37 [00:15<00:01,  2.48it/s]\u001b[A\n",
      " 95%|█████████▍| 35/37 [00:15<00:00,  2.32it/s]\u001b[A\n",
      "100%|██████████| 37/37 [00:16<00:00,  2.30it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [02:18<06:38, 13.76s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/32 [00:05<02:40,  5.17s/it]\u001b[A\n",
      " 19%|█▉        | 6/32 [00:05<00:18,  1.44it/s]\u001b[A\n",
      " 53%|█████▎    | 17/32 [00:09<00:06,  2.18it/s]\u001b[A\n",
      " 56%|█████▋    | 18/32 [00:10<00:06,  2.14it/s]\u001b[A\n",
      " 88%|████████▊ | 28/32 [00:10<00:00,  4.32it/s]\u001b[A\n",
      " 94%|█████████▍| 30/32 [00:11<00:00,  3.63it/s]\u001b[A\n",
      "100%|██████████| 32/32 [00:11<00:00,  2.70it/s]\u001b[A\n",
      " 30%|███       | 12/40 [02:31<06:17, 13.48s/it]\n",
      "  0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/38 [00:05<03:12,  5.21s/it]\u001b[A\n",
      " 45%|████▍     | 17/38 [00:08<00:08,  2.37it/s]\u001b[A\n",
      " 47%|████▋     | 18/38 [00:08<00:08,  2.41it/s]\u001b[A\n",
      " 53%|█████▎    | 20/38 [00:09<00:07,  2.56it/s]\u001b[A\n",
      " 76%|███████▋  | 29/38 [00:11<00:02,  3.50it/s]\u001b[A\n",
      " 82%|████████▏ | 31/38 [00:11<00:01,  3.83it/s]\u001b[A\n",
      "100%|██████████| 38/38 [00:13<00:00,  2.80it/s]\u001b[A\n",
      " 32%|███▎      | 13/40 [02:46<06:12, 13.80s/it]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/30 [00:04<02:14,  4.64s/it]\u001b[A\n",
      "  7%|▋         | 2/30 [00:05<01:00,  2.15s/it]\u001b[A\n",
      " 40%|████      | 12/30 [00:05<00:04,  4.12it/s]\u001b[A\n",
      " 57%|█████▋    | 17/30 [00:09<00:05,  2.17it/s]\u001b[A\n",
      " 67%|██████▋   | 20/30 [00:09<00:03,  2.61it/s]\u001b[A\n",
      " 77%|███████▋  | 23/30 [00:09<00:02,  3.32it/s]\u001b[A\n",
      " 83%|████████▎ | 25/30 [00:10<00:01,  3.91it/s]\u001b[A\n",
      " 90%|█████████ | 27/30 [00:10<00:00,  3.85it/s]\u001b[A\n",
      "100%|██████████| 30/30 [00:11<00:00,  2.64it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [02:58<05:46, 13.33s/it]\n",
      "  0%|          | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/31 [00:04<02:24,  4.83s/it]\u001b[A\n",
      " 55%|█████▍    | 17/31 [00:09<00:06,  2.17it/s]\u001b[A\n",
      " 58%|█████▊    | 18/31 [00:10<00:06,  2.03it/s]\u001b[A\n",
      " 65%|██████▍   | 20/31 [00:10<00:04,  2.31it/s]\u001b[A\n",
      " 94%|█████████▎| 29/31 [00:11<00:00,  3.60it/s]\u001b[A\n",
      "100%|██████████| 31/31 [00:11<00:00,  2.62it/s]\u001b[A\n",
      " 38%|███▊      | 15/40 [03:11<05:29, 13.18s/it]\n",
      "  0%|          | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/31 [00:05<02:40,  5.34s/it]\u001b[A\n",
      " 10%|▉         | 3/31 [00:05<00:40,  1.44s/it]\u001b[A\n",
      " 13%|█▎        | 4/31 [00:05<00:26,  1.01it/s]\u001b[A\n",
      " 16%|█▌        | 5/31 [00:05<00:18,  1.44it/s]\u001b[A\n",
      " 55%|█████▍    | 17/31 [00:09<00:05,  2.68it/s]\u001b[A\n",
      " 58%|█████▊    | 18/31 [00:09<00:04,  2.77it/s]\u001b[A\n",
      " 65%|██████▍   | 20/31 [00:09<00:03,  3.35it/s]\u001b[A\n",
      " 68%|██████▊   | 21/31 [00:10<00:02,  3.46it/s]\u001b[A\n",
      " 84%|████████▍ | 26/31 [00:10<00:00,  5.88it/s]\u001b[A\n",
      " 90%|█████████ | 28/31 [00:10<00:00,  5.14it/s]\u001b[A\n",
      " 94%|█████████▎| 29/31 [00:12<00:00,  2.92it/s]\u001b[A\n",
      "100%|██████████| 31/31 [00:12<00:00,  2.49it/s]\u001b[A\n",
      " 40%|████      | 16/40 [03:24<05:18, 13.29s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/39 [00:04<02:59,  4.72s/it]\u001b[A\n",
      " 13%|█▎        | 5/39 [00:04<00:24,  1.37it/s]\u001b[A\n",
      " 21%|██        | 8/39 [00:04<00:12,  2.51it/s]\u001b[A\n",
      " 44%|████▎     | 17/39 [00:09<00:09,  2.21it/s]\u001b[A\n",
      " 69%|██████▉   | 27/39 [00:09<00:02,  4.28it/s]\u001b[A\n",
      " 85%|████████▍ | 33/39 [00:13<00:02,  2.82it/s]\u001b[A\n",
      " 90%|████████▉ | 35/39 [00:14<00:01,  2.70it/s]\u001b[A\n",
      " 95%|█████████▍| 37/39 [00:15<00:00,  2.66it/s]\u001b[A\n",
      "100%|██████████| 39/39 [00:15<00:00,  2.51it/s]\u001b[A\n",
      " 42%|████▎     | 17/40 [03:41<05:27, 14.26s/it]\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▎         | 1/28 [00:04<02:10,  4.82s/it]\u001b[A\n",
      " 18%|█▊        | 5/28 [00:05<00:17,  1.28it/s]\u001b[A\n",
      " 61%|██████    | 17/28 [00:08<00:04,  2.42it/s]\u001b[A\n",
      " 64%|██████▍   | 18/28 [00:09<00:04,  2.29it/s]\u001b[A\n",
      " 75%|███████▌  | 21/28 [00:10<00:02,  2.78it/s]\u001b[A\n",
      "100%|██████████| 28/28 [00:11<00:00,  2.48it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [03:53<04:59, 13.63s/it]\n",
      "  0%|          | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/43 [00:05<04:08,  5.92s/it]\u001b[A\n",
      " 14%|█▍        | 6/43 [00:06<00:29,  1.27it/s]\u001b[A\n",
      " 40%|███▉      | 17/43 [00:09<00:11,  2.28it/s]\u001b[A\n",
      " 42%|████▏     | 18/43 [00:09<00:10,  2.37it/s]\u001b[A\n",
      " 44%|████▍     | 19/43 [00:10<00:09,  2.49it/s]\u001b[A\n",
      " 49%|████▉     | 21/43 [00:10<00:07,  3.01it/s]\u001b[A\n",
      " 60%|██████    | 26/43 [00:10<00:03,  4.31it/s]\u001b[A\n",
      " 74%|███████▍  | 32/43 [00:13<00:03,  3.22it/s]\u001b[A\n",
      " 77%|███████▋  | 33/43 [00:14<00:03,  2.54it/s]\u001b[A\n",
      " 84%|████████▎ | 36/43 [00:14<00:02,  3.37it/s]\u001b[A\n",
      "100%|██████████| 43/43 [00:16<00:00,  2.63it/s]\u001b[A\n",
      " 48%|████▊     | 19/40 [04:11<05:10, 14.77s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/39 [00:04<03:02,  4.81s/it]\u001b[A\n",
      " 10%|█         | 4/39 [00:05<00:34,  1.02it/s]\u001b[A\n",
      " 23%|██▎       | 9/39 [00:05<00:10,  2.81it/s]\u001b[A\n",
      " 44%|████▎     | 17/39 [00:08<00:08,  2.50it/s]\u001b[A\n",
      " 49%|████▊     | 19/39 [00:09<00:07,  2.55it/s]\u001b[A\n",
      " 51%|█████▏    | 20/39 [00:09<00:07,  2.43it/s]\u001b[A\n",
      " 85%|████████▍ | 33/39 [00:13<00:01,  3.39it/s]\u001b[A\n",
      " 87%|████████▋ | 34/39 [00:13<00:01,  3.30it/s]\u001b[A\n",
      " 90%|████████▉ | 35/39 [00:13<00:01,  3.17it/s]\u001b[A\n",
      " 92%|█████████▏| 36/39 [00:14<00:01,  2.81it/s]\u001b[A\n",
      "100%|██████████| 39/39 [00:15<00:00,  2.59it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [04:26<05:02, 15.12s/it]\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/19 [00:05<01:35,  5.31s/it]\u001b[A\n",
      "100%|██████████| 19/19 [00:10<00:00,  1.81it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [04:38<04:26, 14.01s/it]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/42 [00:05<03:30,  5.14s/it]\u001b[A\n",
      "  5%|▍         | 2/42 [00:05<01:29,  2.24s/it]\u001b[A\n",
      " 14%|█▍        | 6/42 [00:05<00:21,  1.70it/s]\u001b[A\n",
      " 40%|████      | 17/42 [00:09<00:09,  2.64it/s]\u001b[A\n",
      " 43%|████▎     | 18/42 [00:09<00:09,  2.57it/s]\u001b[A\n",
      " 52%|█████▏    | 22/42 [00:09<00:05,  3.60it/s]\u001b[A\n",
      " 74%|███████▍  | 31/42 [00:10<00:01,  6.48it/s]\u001b[A\n",
      " 79%|███████▊  | 33/42 [00:14<00:03,  2.44it/s]\u001b[A\n",
      " 83%|████████▎ | 35/42 [00:15<00:02,  2.41it/s]\u001b[A\n",
      " 86%|████████▌ | 36/42 [00:15<00:02,  2.55it/s]\u001b[A\n",
      " 95%|█████████▌| 40/42 [00:15<00:00,  3.79it/s]\u001b[A\n",
      "100%|██████████| 42/42 [00:15<00:00,  2.66it/s]\u001b[A\n",
      " 55%|█████▌    | 22/40 [04:55<04:26, 14.82s/it]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/24 [00:05<01:55,  5.02s/it]\u001b[A\n",
      " 58%|█████▊    | 14/24 [00:05<00:02,  3.50it/s]\u001b[A\n",
      " 71%|███████   | 17/24 [00:08<00:03,  2.17it/s]\u001b[A\n",
      " 79%|███████▉  | 19/24 [00:09<00:02,  2.16it/s]\u001b[A\n",
      "100%|██████████| 24/24 [00:11<00:00,  2.15it/s]\u001b[A\n",
      " 57%|█████▊    | 23/40 [05:07<03:58, 14.01s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:04<01:24,  4.99s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:05<00:33,  2.12s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:05<00:08,  1.50it/s]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:05<00:00,  5.84it/s]\u001b[A\n",
      "100%|██████████| 18/18 [00:11<00:00,  1.62it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [05:19<03:34, 13.41s/it]\n",
      "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/23 [00:05<01:55,  5.25s/it]\u001b[A\n",
      " 13%|█▎        | 3/23 [00:05<00:29,  1.47s/it]\u001b[A\n",
      " 74%|███████▍  | 17/23 [00:08<00:02,  2.55it/s]\u001b[A\n",
      " 83%|████████▎ | 19/23 [00:09<00:01,  2.56it/s]\u001b[A\n",
      " 87%|████████▋ | 20/23 [00:10<00:01,  2.12it/s]\u001b[A\n",
      "100%|██████████| 23/23 [00:11<00:00,  1.98it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [05:31<03:17, 13.15s/it]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/41 [00:05<03:22,  5.07s/it]\u001b[A\n",
      "  5%|▍         | 2/41 [00:05<01:37,  2.50s/it]\u001b[A\n",
      " 41%|████▏     | 17/41 [00:09<00:09,  2.58it/s]\u001b[A\n",
      " 44%|████▍     | 18/41 [00:09<00:08,  2.69it/s]\u001b[A\n",
      " 46%|████▋     | 19/41 [00:09<00:08,  2.68it/s]\u001b[A\n",
      " 68%|██████▊   | 28/41 [00:10<00:02,  4.76it/s]\u001b[A\n",
      " 80%|████████  | 33/41 [00:13<00:02,  3.09it/s]\u001b[A\n",
      " 83%|████████▎ | 34/41 [00:13<00:02,  3.09it/s]\u001b[A\n",
      " 85%|████████▌ | 35/41 [00:14<00:01,  3.04it/s]\u001b[A\n",
      " 88%|████████▊ | 36/41 [00:14<00:01,  2.76it/s]\u001b[A\n",
      "100%|██████████| 41/41 [00:15<00:00,  2.61it/s]\u001b[A\n",
      " 65%|██████▌   | 26/40 [05:48<03:18, 14.20s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/39 [00:04<03:08,  4.96s/it]\u001b[A\n",
      " 10%|█         | 4/39 [00:05<00:33,  1.03it/s]\u001b[A\n",
      " 44%|████▎     | 17/39 [00:08<00:08,  2.71it/s]\u001b[A\n",
      " 49%|████▊     | 19/39 [00:09<00:07,  2.61it/s]\u001b[A\n",
      " 54%|█████▍    | 21/39 [00:09<00:06,  2.97it/s]\u001b[A\n",
      " 74%|███████▍  | 29/39 [00:09<00:01,  5.55it/s]\u001b[A\n",
      " 85%|████████▍ | 33/39 [00:12<00:01,  3.15it/s]\u001b[A\n",
      " 90%|████████▉ | 35/39 [00:14<00:01,  2.33it/s]\u001b[A\n",
      "100%|██████████| 39/39 [00:14<00:00,  2.63it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [06:04<03:10, 14.67s/it]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/24 [00:04<01:51,  4.86s/it]\u001b[A\n",
      " 29%|██▉       | 7/24 [00:05<00:09,  1.88it/s]\u001b[A\n",
      " 42%|████▏     | 10/24 [00:05<00:04,  2.80it/s]\u001b[A\n",
      " 58%|█████▊    | 14/24 [00:05<00:02,  3.58it/s]\u001b[A\n",
      " 71%|███████   | 17/24 [00:08<00:03,  2.07it/s]\u001b[A\n",
      " 79%|███████▉  | 19/24 [00:09<00:02,  2.36it/s]\u001b[A\n",
      "100%|██████████| 24/24 [00:11<00:00,  2.16it/s]\u001b[A\n",
      " 70%|███████   | 28/40 [06:16<02:46, 13.88s/it]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/34 [00:04<02:36,  4.76s/it]\u001b[A\n",
      " 12%|█▏        | 4/34 [00:05<00:30,  1.02s/it]\u001b[A\n",
      " 15%|█▍        | 5/34 [00:05<00:24,  1.19it/s]\u001b[A\n",
      " 50%|█████     | 17/34 [00:09<00:07,  2.36it/s]\u001b[A\n",
      " 53%|█████▎    | 18/34 [00:10<00:06,  2.35it/s]\u001b[A\n",
      " 74%|███████▎  | 25/34 [00:10<00:02,  3.86it/s]\u001b[A\n",
      " 79%|███████▉  | 27/34 [00:12<00:02,  2.93it/s]\u001b[A\n",
      " 82%|████████▏ | 28/34 [00:12<00:02,  2.89it/s]\u001b[A\n",
      "100%|██████████| 34/34 [00:14<00:00,  2.29it/s]\u001b[A\n",
      " 72%|███████▎  | 29/40 [06:32<02:39, 14.46s/it]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/30 [00:04<02:18,  4.77s/it]\u001b[A\n",
      "  7%|▋         | 2/30 [00:04<00:57,  2.06s/it]\u001b[A\n",
      " 10%|█         | 3/30 [00:05<00:36,  1.36s/it]\u001b[A\n",
      " 57%|█████▋    | 17/30 [00:09<00:04,  2.66it/s]\u001b[A\n",
      " 60%|██████    | 18/30 [00:09<00:04,  2.78it/s]\u001b[A\n",
      " 67%|██████▋   | 20/30 [00:10<00:03,  2.85it/s]\u001b[A\n",
      " 87%|████████▋ | 26/30 [00:10<00:00,  4.51it/s]\u001b[A\n",
      "100%|██████████| 30/30 [00:12<00:00,  2.42it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [06:45<02:21, 14.11s/it]\n",
      "  0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/29 [00:05<02:22,  5.09s/it]\u001b[A\n",
      " 28%|██▊       | 8/29 [00:05<00:10,  2.07it/s]\u001b[A\n",
      " 59%|█████▊    | 17/29 [00:09<00:05,  2.11it/s]\u001b[A\n",
      " 66%|██████▌   | 19/29 [00:10<00:04,  2.18it/s]\u001b[A\n",
      "100%|██████████| 29/29 [00:11<00:00,  2.46it/s]\u001b[A\n",
      " 78%|███████▊  | 31/40 [06:58<02:03, 13.69s/it]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/22 [00:05<01:45,  5.04s/it]\u001b[A\n",
      "100%|██████████| 22/22 [00:11<00:00,  1.98it/s]\u001b[A\n",
      " 80%|████████  | 32/40 [07:10<01:45, 13.19s/it]\n",
      "  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/26 [00:04<02:03,  4.93s/it]\u001b[A\n",
      " 19%|█▉        | 5/26 [00:05<00:16,  1.28it/s]\u001b[A\n",
      " 27%|██▋       | 7/26 [00:05<00:11,  1.59it/s]\u001b[A\n",
      " 65%|██████▌   | 17/26 [00:09<00:03,  2.46it/s]\u001b[A\n",
      " 69%|██████▉   | 18/26 [00:09<00:03,  2.37it/s]\u001b[A\n",
      "100%|██████████| 26/26 [00:11<00:00,  2.25it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [07:22<01:30, 12.97s/it]\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/19 [00:04<01:26,  4.80s/it]\u001b[A\n",
      "100%|██████████| 19/19 [00:11<00:00,  1.71it/s]\u001b[A\n",
      " 85%|████████▌ | 34/40 [07:34<01:16, 12.68s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/25 [00:04<01:49,  4.56s/it]\u001b[A\n",
      " 16%|█▌        | 4/25 [00:04<00:19,  1.10it/s]\u001b[A\n",
      " 32%|███▏      | 8/25 [00:05<00:06,  2.43it/s]\u001b[A\n",
      " 68%|██████▊   | 17/25 [00:08<00:03,  2.49it/s]\u001b[A\n",
      " 72%|███████▏  | 18/25 [00:08<00:02,  2.55it/s]\u001b[A\n",
      " 92%|█████████▏| 23/25 [00:09<00:00,  3.76it/s]\u001b[A\n",
      "100%|██████████| 25/25 [00:11<00:00,  2.26it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [07:46<01:02, 12.46s/it]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/33 [00:04<02:29,  4.66s/it]\u001b[A\n",
      "  6%|▌         | 2/33 [00:04<01:02,  2.01s/it]\u001b[A\n",
      "  9%|▉         | 3/33 [00:05<00:35,  1.18s/it]\u001b[A\n",
      " 12%|█▏        | 4/33 [00:05<00:22,  1.30it/s]\u001b[A\n",
      " 27%|██▋       | 9/33 [00:05<00:06,  3.63it/s]\u001b[A\n",
      " 52%|█████▏    | 17/33 [00:08<00:05,  2.78it/s]\u001b[A\n",
      " 58%|█████▊    | 19/33 [00:09<00:04,  3.27it/s]\u001b[A\n",
      " 61%|██████    | 20/33 [00:10<00:05,  2.48it/s]\u001b[A\n",
      " 85%|████████▍ | 28/33 [00:10<00:01,  4.81it/s]\u001b[A\n",
      " 91%|█████████ | 30/33 [00:11<00:00,  3.56it/s]\u001b[A\n",
      " 94%|█████████▍| 31/33 [00:12<00:00,  2.90it/s]\u001b[A\n",
      "100%|██████████| 33/33 [00:14<00:00,  2.24it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [08:02<00:53, 13.41s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/25 [00:05<02:09,  5.40s/it]\u001b[A\n",
      " 12%|█▏        | 3/25 [00:05<00:32,  1.46s/it]\u001b[A\n",
      " 68%|██████▊   | 17/25 [00:09<00:03,  2.34it/s]\u001b[A\n",
      " 80%|████████  | 20/25 [00:09<00:01,  2.88it/s]\u001b[A\n",
      "100%|██████████| 25/25 [00:11<00:00,  2.26it/s]\u001b[A\n",
      " 92%|█████████▎| 37/40 [08:14<00:38, 12.98s/it]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/33 [00:04<02:27,  4.60s/it]\u001b[A\n",
      "  6%|▌         | 2/33 [00:04<01:00,  1.96s/it]\u001b[A\n",
      " 18%|█▊        | 6/33 [00:04<00:12,  2.10it/s]\u001b[A\n",
      " 42%|████▏     | 14/33 [00:05<00:03,  6.19it/s]\u001b[A\n",
      " 55%|█████▍    | 18/33 [00:09<00:07,  2.09it/s]\u001b[A\n",
      " 64%|██████▎   | 21/33 [00:10<00:05,  2.07it/s]\u001b[A\n",
      " 70%|██████▉   | 23/33 [00:11<00:04,  2.36it/s]\u001b[A\n",
      "100%|██████████| 33/33 [00:11<00:00,  2.84it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [08:26<00:25, 12.83s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/47 [00:04<03:41,  4.81s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:05<01:36,  2.14s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:05<00:21,  1.93it/s]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:05<00:13,  2.84it/s]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:05<00:03,  7.99it/s]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:09<00:11,  2.32it/s]\u001b[A\n",
      " 51%|█████     | 24/47 [00:10<00:07,  2.99it/s]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:10<00:06,  3.39it/s]\u001b[A\n",
      " 70%|███████   | 33/47 [00:13<00:04,  2.97it/s]\u001b[A\n",
      " 74%|███████▍  | 35/47 [00:13<00:04,  2.87it/s]\u001b[A\n",
      " 79%|███████▊  | 37/47 [00:14<00:03,  3.11it/s]\u001b[A\n",
      " 87%|████████▋ | 41/47 [00:14<00:01,  4.40it/s]\u001b[A\n",
      " 91%|█████████▏| 43/47 [00:15<00:01,  3.74it/s]\u001b[A\n",
      " 94%|█████████▎| 44/47 [00:16<00:01,  2.41it/s]\u001b[A\n",
      "100%|██████████| 47/47 [00:17<00:00,  2.74it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [08:44<00:14, 14.41s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/21 [00:04<01:37,  4.88s/it]\u001b[A\n",
      " 19%|█▉        | 4/21 [00:05<00:17,  1.02s/it]\u001b[A\n",
      " 81%|████████  | 17/21 [00:09<00:01,  2.31it/s]\u001b[A\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.85it/s]\u001b[A\n",
      "100%|██████████| 40/40 [08:56<00:00, 13.42s/it]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "\n",
    "with open(\"clean_data_list.pkl\",\"rb\") as f:\n",
    "      clean_data = pickle.load(f)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Example function with error handling\n",
    "def process_sample(sample,nlp=nlp):\n",
    "    try:\n",
    "        text = sample[0]\n",
    "        word_level = layer_1(text,nlp)\n",
    "        (l2_embeddings,l2_matrix,l2_masks) = layer_2_sentence_level(text,nlp)\n",
    "        concept_level = layer_3_concept_level(text,nlp)\n",
    "        layer_dict = {'layer_1': word_level,\n",
    "        'layer_2': (l2_embeddings,l2_matrix),\n",
    "        'layer_3': concept_level,\n",
    "        'masks': l2_masks\n",
    "        })\n",
    "        return [text,sample[1],layer_dict]\n",
    "    except Exception as e:\n",
    "        pprint(f\"Error processing sample {e}\")\n",
    "        return None  # Or handle as needed\n",
    "\n",
    "# Parallelize the processing using ProcessPoolExecutor\n",
    "\n",
    "from collections import defaultdict\n",
    "test_results = defaultdict(list)\n",
    "#remaining_keys = list()\n",
    "for id in tqdm(clean_data.keys()):\n",
    "  samples = clean_data[id]\n",
    "  results = []\n",
    "  for [sample,label] in samples:\n",
    "      results = process_sample(sample)\n",
    "      results.append(sample)\n",
    "  test_results[id] = results\n",
    "\n",
    "\n",
    "#emb,adj,tokens = layer_1(x,nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6058e53b-92ec-4972-be91-6a6c3ba5b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id,samples in clean_data.items():\n",
    "    print(id)\n",
    "    for (label,sample) in samples:\n",
    "        print(sample)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a3d3435-eb7d-4a4d-a463-41cceb6752d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_data[\"A01\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb9a39-4489-4a46-9cc9-621517f10484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Load SpaCy globally\n",
    "nlp_global = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load clean_data\n",
    "with open(\"clean_data_list.pkl\", \"rb\") as f:\n",
    "    clean_data = pickle.load(f)\n",
    "\n",
    "# Worker initialization\n",
    "def init_worker():\n",
    "    \"\"\"\n",
    "    Initializes worker with a SpaCy model to avoid pickling issues.\n",
    "    \"\"\"\n",
    "    global nlp_worker\n",
    "    nlp_worker = spacy.blank(\"en\")  # Lightweight alternative for multiprocessing\n",
    "\n",
    "# Process a single sample\n",
    "def process_sample(sample):\n",
    "    try:\n",
    "        global nlp_worker\n",
    "        text, label = sample[0], sample[1]\n",
    "        layer_1_output = layer_1(text, nlp_worker)\n",
    "        layer_2_output = layer_2_sentence_level(text, nlp_worker)\n",
    "        layer_3_output = layer_3_concept_level(text, nlp_worker)\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"label\": label,\n",
    "            \"layer_1\": layer_1_output,\n",
    "            \"layer_2\": layer_2_output,\n",
    "            \"layer_3\": layer_3_output,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"text\": sample[0], \"label\": sample[1]}\n",
    "\n",
    "# Process data for a single ID\n",
    "def process_data_for_id(data_for_id):\n",
    "    \"\"\"\n",
    "    Process samples for a single ID in parallel.\n",
    "    \"\"\"\n",
    "    id, samples = data_for_id\n",
    "    results = []\n",
    "    for sample in samples:\n",
    "        result = process_sample(sample)\n",
    "        if result and \"error\" not in result:\n",
    "            results.append(result)\n",
    "    return id, results\n",
    "\n",
    "# Parallel processing\n",
    "def process_samples_in_parallel(clean_data, max_workers=2, batch_size=50):\n",
    "    \"\"\"\n",
    "    Processes clean_data in parallel.\n",
    "\n",
    "    Args:\n",
    "        clean_data (dict): Dictionary of {id: list of samples}.\n",
    "        max_workers (int): Number of worker processes.\n",
    "        batch_size (int): Number of IDs processed per batch.\n",
    "\n",
    "    Returns:\n",
    "        dict: Results for all IDs.\n",
    "    \"\"\"\n",
    "    test_results = defaultdict(list)\n",
    "    id_sample_pairs = list(clean_data.items())\n",
    "    batch_size = 5\n",
    "    # Use ProcessPoolExecutor for parallel processing\n",
    "    with ProcessPoolExecutor(max_workers=max_workers, initializer=init_worker) as executor:\n",
    "        # Batch process IDs\n",
    "        for i in tqdm(range(0, len(id_sample_pairs), batch_size), desc=\"Processing Batches\"):\n",
    "            batch = id_sample_pairs[i : i + batch_size]\n",
    "            for id, results in executor.map(process_data_for_id, batch):\n",
    "                test_results[id].extend(results)\n",
    "\n",
    "    return test_results\n",
    "\n",
    "# Execute the processing\n",
    "test_results = process_samples_in_parallel(clean_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e6b50-2dfb-467e-9f84-59128ae7f090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
